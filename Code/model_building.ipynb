{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import the libraries\n",
    "#import numpy as np\n",
    "#import pandas as pd\n",
    "#import mmlspark\n",
    "\n",
    "#import subprocess\n",
    "#import sys\n",
    "#import os\n",
    "#import re\n",
    "#import time\n",
    "#import atexit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#from pyspark.sql import Row\n",
    "#from pyspark.sql.functions import col, unix_timestamp, round\n",
    "\n",
    "#from pyspark import SparkConf\n",
    "#from pyspark import SparkContext\n",
    "#from pyspark import SQLContext\n",
    "#import pyspark.sql.functions as F\n",
    "#from pyspark.sql.functions import concat, col, udf, lag, date_add, explode, lit, unix_timestamp\n",
    "#from pyspark.sql.functions import month, weekofyear, dayofmonth\n",
    "#from pyspark.sql.functions import datediff, to_date, lit, unix_timestamp\n",
    "# from pyspark.sql.types import *\n",
    "#from pyspark.sql.types import DateType\n",
    "# from pyspark.sql.dataframe import *\n",
    "#from pyspark.sql.window import Window\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.classification import *\n",
    "#from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, VectorIndexer\n",
    "#from pyspark.ml.feature import StandardScaler, PCA, RFormula\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "#from pyspark.mllib.stat import Statistics\n",
    "#from pyspark.sql.functions import UserDefinedFunction\n",
    "#from pyspark.sql.functions import *\n",
    "\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorIndexer, VectorAssembler, RFormula\n",
    "#from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "#from sklearn.metrics import roc_curve,auc\n",
    "#from pyspark.sql.functions import month, weekofyear, dayofmonth\n",
    "#from pyspark.ml.feature import ChiSqSelector\n",
    "#from pyspark.ml.linalg import Vectors\n",
    "#from pyspark.ml.feature import StandardScaler\n",
    "#from pyspark.ml.feature import PCA\n",
    "#from pyspark.ml.feature import MinMaxScaler\n",
    "#from pyspark.sql.types import DoubleType\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the previous created final dataset into the workspace\n",
    "from azure.storage.blob import BlockBlobService\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# define parameters \n",
    "ACCOUNT_NAME = \"pdmvienna\"\n",
    "ACCOUNT_KEY = \"PDuXK61GpmMVWMrWdvr29THbPdlOXa61fN5RfgQV/jBO8berC1zLzZ678Nxrx+D3CRp4+ZvSff9al+lrUh8qUQ==\"\n",
    "CONTAINER_NAME = \"featureengineering\"\n",
    "\n",
    "# define your blob service     \n",
    "my_service = BlockBlobService(account_name=ACCOUNT_NAME, account_key=ACCOUNT_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# create a local path where to store the results later.\n",
    "LOCAL_DIRECT = 'model_result.parquet'\n",
    "if not os.path.exists(LOCAL_DIRECT):\n",
    "    os.makedirs(LOCAL_DIRECT)\n",
    "    print('DONE creating a local directory!')\n",
    "\n",
    "# define your blob service     \n",
    "my_service = BlockBlobService(account_name=ACCOUNT_NAME, account_key=ACCOUNT_KEY)\n",
    "\n",
    "# download the entire parquet result folder to local path for a new run \n",
    "for blob in my_service.list_blobs(CONTAINER_NAME):\n",
    "    if 'featureengineering_files.parquet' in blob.name:\n",
    "        local_file = os.path.join(LOCAL_DIRECT, os.path.basename(blob.name))\n",
    "        my_service.get_blob_to_path(CONTAINER_NAME, blob.name, local_file)\n",
    "\n",
    "data = spark.read.parquet('model_result.parquet')\n",
    "#data.persist()\n",
    "data.show(10)\n",
    "print('Feature engineering final dataset files loaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the train/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define list of input columns for downstream modeling - note model variable was removed as string was not supported\n",
    "input_features = [\n",
    "'volt_rollingmean_3',\n",
    "'rotate_rollingmean_3',\n",
    "'pressure_rollingmean_3',\n",
    "'vibration_rollingmean_3',\n",
    "'volt_rollingmean_24',\n",
    "'rotate_rollingmean_24',\n",
    "'pressure_rollingmean_24',\n",
    "'vibration_rollingmean_24',\n",
    "'volt_rollingstd_3',\n",
    "'rotate_rollingstd_3',\n",
    "'pressure_rollingstd_3',\n",
    "'vibration_rollingstd_3',\n",
    "'volt_rollingstd_24',\n",
    "'rotate_rollingstd_24',\n",
    "'pressure_rollingstd_24',\n",
    "'vibration_rollingstd_24',\n",
    "'error1sum_rollingmean_24',\n",
    "'error2sum_rollingmean_24',\n",
    "'error3sum_rollingmean_24',\n",
    "'error4sum_rollingmean_24',\n",
    "'error5sum_rollingmean_24',\n",
    "'comp1sum',\n",
    "'comp2sum',\n",
    "'comp3sum',\n",
    "'comp4sum',\n",
    "'age',\n",
    "'model_encoded'    \n",
    "]\n",
    "\n",
    "label_var = ['label_e']\n",
    "key_cols =['machineID','dt_truncated']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# assemble features\n",
    "va = VectorAssembler(inputCols=(input_features), outputCol='features')\n",
    "data = va.transform(data).select('machineID','dt_truncated','label_e','features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set maxCategories so features with > 10 distinct values are treated as continuous.\n",
    "featureIndexer = VectorIndexer(inputCol=\"features\", \n",
    "                               outputCol=\"indexedFeatures\", \n",
    "                               maxCategories=10).fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit on whole dataset to include all labels in index\n",
    "labelIndexer = StringIndexer(inputCol=\"label_e\", outputCol=\"indexedLabel\").fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split the data into train/test based on date\n",
    "training = data.filter(data.dt_truncated > \"2015-01-01\").filter(data.dt_truncated < \"2015-09-30\")\n",
    "testing = data.filter(data.dt_truncated > \"2015-09-30\")\n",
    "\n",
    "print(training.count())\n",
    "print(testing.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train a RandomForest model.\n",
    "rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", numTrees=10)\n",
    "\n",
    "# chain indexers and forest in a Pipeline\n",
    "pipeline_rf = Pipeline(stages=[labelIndexer, featureIndexer, rf])\n",
    "\n",
    "# train model.  This also runs the indexers.\n",
    "model_rf = pipeline_rf.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make predictions.\n",
    "predictions_rf = model_rf.transform(testing)\n",
    "predictions_rf.groupby('indexedLabel', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_rf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictionAndLabels = predictions_rf.select(\"indexedLabel\", \"prediction\").rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\")\n",
    "print(\"Accuracy = %g\" % evaluator.evaluate(predictions_rf, {evaluator.metricName: \"accuracy\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Weighted Precision = %g\" % evaluator.evaluate(predictions_rf, {evaluator.metricName: \"weightedPrecision\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Weighted Recall = %g\" % evaluator.evaluate(predictions_rf, {evaluator.metricName: \"weightedRecall\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"F1 = %g\" % evaluator.evaluate(predictions_rf, {evaluator.metricName: \"f1\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train a DT model.\n",
    "dt = DecisionTreeClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\")\n",
    "\n",
    "# chain indexers and forest in a Pipeline\n",
    "pipeline_dt = Pipeline(stages=[labelIndexer, featureIndexer, dt])\n",
    "\n",
    "# train model.  This also runs the indexers.\n",
    "model_dt = pipeline_dt.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make predictions.\n",
    "predictions_dt = model_dt.transform(testing)\n",
    "predictions_dt.groupby('indexedLabel', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_dt.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictionAndLabels = predictions_dt.select(\"indexedLabel\", \"prediction\").rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\")\n",
    "print(\"Accuracy = %g\" % evaluator.evaluate(predictions_dt, {evaluator.metricName: \"accuracy\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Weighted Precision = %g\" % evaluator.evaluate(predictions_dt, {evaluator.metricName: \"weightedPrecision\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Weighted Recall = %g\" % evaluator.evaluate(predictions_dt, {evaluator.metricName: \"weightedRecall\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"F1 = %g\" % evaluator.evaluate(predictions_dt, {evaluator.metricName: \"f1\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write the final model as parquet file in blob location \n",
    "# https://github.com/Azure/ViennaDocs/blob/master/Documentation/UsingBlobForStorage.md\n",
    "\n",
    "# you decide to partition the dataframe into three files and save them in the current folder.\n",
    "# if you wish to visualize them in the run history Output Files, specify the path as \n",
    "# './outputs/multiple_files.parquet'.\n",
    "#model_dt.write.mode('overwrite').parquet('model.parquet')\n",
    "model_dt.save('model.parquet')\n",
    "\n",
    "# unlike the single file case, for multiple files we need to first delete results \n",
    "# from the previous run before uploading.\n",
    "for blob in my_service.list_blobs(CONTAINER_NAME):\n",
    "    if 'model.parquet' in blob.name:\n",
    "        my_service.delete_blob(CONTAINER_NAME, blob.name)\n",
    "\n",
    "print(\"Model files saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hack docker",
   "language": "python",
   "name": "hack_docker"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

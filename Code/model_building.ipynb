{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Model Building\n",
    "\n",
    "The final feature engineered dataset is then split into two namely a train and a test dataset based on a date-time stamp. Then two models namely a Random Forest Classifier and Decision Tree Classifier are built on the training dataset and then scored on the test dataset.\n",
    "\n",
    "In this notebook, we will load the data stored in Azure Blob containers in the previous Feature Engineering notebook (Code/feature_engineering.ipynb). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import the libraries\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# for creating pipelines and model\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, VectorIndexer\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml.classification import *\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from azure.storage.blob import BlockBlobService\n",
    "from azure.storage.blob import PublicAccess\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data from Azure Blob storage container \n",
    "\n",
    "We have previously feature engineering on the dataset. \n",
    "\n",
    "We'll load this file from blob, and create our models here. Based on the results we will deploy one of these models in the next notebook. \n",
    "\n",
    "Since the Azure Blob storage account name and account key are not passed between notebooks, you'll need to provide those here again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Enter your Azure blob storage details here \n",
    "ACCOUNT_NAME = \"pdmamlworkbench\"   ## \"<your blob storage account name>\"\n",
    "\n",
    "# You can find the account key under the _Access Keys_ link in the \n",
    "# [Azure Portal](portal.azure.com) page for your Azure storage container.\n",
    "ACCOUNT_KEY = \"O5uLzNKX7o+ZHFXtHDyS87SIev9QHlkdX2IhIbxYwhRo7sA9zp45HOOFFttUp4r0LyWCcLQ0cCA7l+e8Ct3Yew==\" ## \"<your blob storage account key>\"\n",
    "\n",
    "#-------------------------------------------------------------------------------------------\n",
    "# The data from the feature engineering note book is stored in the feature engineering container.\n",
    "CONTAINER_NAME = CONTAINER_NAME = \"featureengineering\"\n",
    "\n",
    "# Connect to your blob service     \n",
    "my_service = BlockBlobService(account_name=ACCOUNT_NAME, account_key=ACCOUNT_KEY)\n",
    "\n",
    "# We will store and read each of these data sets in blob storage in an \n",
    "# Azure Storage Container on your Azure subscription.\n",
    "# See https://github.com/Azure/ViennaDocs/blob/master/Documentation/UsingBlobForStorage.md\n",
    "# for details.\n",
    "\n",
    "# This is the final feature data file.\n",
    "FEATURES_LOCAL_DIRECT = 'featureengineering_files.parquet'\n",
    "\n",
    "# This is where we store the final model data file.\n",
    "LOCAL_DIRECT = 'model_result.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>machineID</th>\n",
       "      <th>dt_truncated</th>\n",
       "      <th>volt_rollingmean_3</th>\n",
       "      <th>rotate_rollingmean_3</th>\n",
       "      <th>pressure_rollingmean_3</th>\n",
       "      <th>vibration_rollingmean_3</th>\n",
       "      <th>volt_rollingmean_24</th>\n",
       "      <th>rotate_rollingmean_24</th>\n",
       "      <th>pressure_rollingmean_24</th>\n",
       "      <th>vibration_rollingmean_24</th>\n",
       "      <th>...</th>\n",
       "      <th>error5sum_rollingmean_24</th>\n",
       "      <th>comp1sum</th>\n",
       "      <th>comp2sum</th>\n",
       "      <th>comp3sum</th>\n",
       "      <th>comp4sum</th>\n",
       "      <th>model</th>\n",
       "      <th>age</th>\n",
       "      <th>model_encoded</th>\n",
       "      <th>failure1</th>\n",
       "      <th>label_e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45</td>\n",
       "      <td>2016-01-01 06:00:00</td>\n",
       "      <td>174.881727</td>\n",
       "      <td>527.816907</td>\n",
       "      <td>117.225971</td>\n",
       "      <td>39.472147</td>\n",
       "      <td>185.926371</td>\n",
       "      <td>470.121966</td>\n",
       "      <td>113.564799</td>\n",
       "      <td>39.936377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>474.000000</td>\n",
       "      <td>459.000000</td>\n",
       "      <td>384.000000</td>\n",
       "      <td>579.000000</td>\n",
       "      <td>model1</td>\n",
       "      <td>14</td>\n",
       "      <td>(0.0, 0.0, 0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45</td>\n",
       "      <td>2016-01-01 03:00:00</td>\n",
       "      <td>188.406674</td>\n",
       "      <td>474.631787</td>\n",
       "      <td>124.261901</td>\n",
       "      <td>38.869583</td>\n",
       "      <td>186.103373</td>\n",
       "      <td>461.103049</td>\n",
       "      <td>112.467296</td>\n",
       "      <td>39.969765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>474.000000</td>\n",
       "      <td>459.000000</td>\n",
       "      <td>384.000000</td>\n",
       "      <td>579.000000</td>\n",
       "      <td>model1</td>\n",
       "      <td>14</td>\n",
       "      <td>(0.0, 0.0, 0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>171.329008</td>\n",
       "      <td>454.871774</td>\n",
       "      <td>123.029121</td>\n",
       "      <td>37.712346</td>\n",
       "      <td>184.493495</td>\n",
       "      <td>458.147521</td>\n",
       "      <td>110.240281</td>\n",
       "      <td>39.621269</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>473.666667</td>\n",
       "      <td>458.666667</td>\n",
       "      <td>383.666667</td>\n",
       "      <td>578.666667</td>\n",
       "      <td>model1</td>\n",
       "      <td>14</td>\n",
       "      <td>(0.0, 0.0, 0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>2015-12-31 21:00:00</td>\n",
       "      <td>187.832175</td>\n",
       "      <td>478.072922</td>\n",
       "      <td>128.126653</td>\n",
       "      <td>38.659306</td>\n",
       "      <td>184.465271</td>\n",
       "      <td>453.473419</td>\n",
       "      <td>107.234582</td>\n",
       "      <td>39.799088</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>473.000000</td>\n",
       "      <td>458.000000</td>\n",
       "      <td>383.000000</td>\n",
       "      <td>578.000000</td>\n",
       "      <td>model1</td>\n",
       "      <td>14</td>\n",
       "      <td>(0.0, 0.0, 0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45</td>\n",
       "      <td>2015-12-31 18:00:00</td>\n",
       "      <td>188.931361</td>\n",
       "      <td>465.157611</td>\n",
       "      <td>115.048540</td>\n",
       "      <td>41.007536</td>\n",
       "      <td>182.153162</td>\n",
       "      <td>454.506948</td>\n",
       "      <td>103.728100</td>\n",
       "      <td>39.916098</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>473.000000</td>\n",
       "      <td>458.000000</td>\n",
       "      <td>383.000000</td>\n",
       "      <td>578.000000</td>\n",
       "      <td>model1</td>\n",
       "      <td>14</td>\n",
       "      <td>(0.0, 0.0, 0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>45</td>\n",
       "      <td>2015-12-31 15:00:00</td>\n",
       "      <td>187.519556</td>\n",
       "      <td>488.409741</td>\n",
       "      <td>98.531106</td>\n",
       "      <td>40.679373</td>\n",
       "      <td>181.066678</td>\n",
       "      <td>457.408755</td>\n",
       "      <td>101.431726</td>\n",
       "      <td>38.982713</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>473.000000</td>\n",
       "      <td>458.000000</td>\n",
       "      <td>383.000000</td>\n",
       "      <td>578.000000</td>\n",
       "      <td>model1</td>\n",
       "      <td>14</td>\n",
       "      <td>(0.0, 0.0, 0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>45</td>\n",
       "      <td>2015-12-31 12:00:00</td>\n",
       "      <td>184.169519</td>\n",
       "      <td>476.258197</td>\n",
       "      <td>103.798398</td>\n",
       "      <td>39.538776</td>\n",
       "      <td>179.502910</td>\n",
       "      <td>451.580197</td>\n",
       "      <td>101.653542</td>\n",
       "      <td>38.605434</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>473.000000</td>\n",
       "      <td>458.000000</td>\n",
       "      <td>383.000000</td>\n",
       "      <td>578.000000</td>\n",
       "      <td>model1</td>\n",
       "      <td>14</td>\n",
       "      <td>(0.0, 0.0, 0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>45</td>\n",
       "      <td>2015-12-31 09:00:00</td>\n",
       "      <td>198.755239</td>\n",
       "      <td>415.146541</td>\n",
       "      <td>101.265224</td>\n",
       "      <td>41.802852</td>\n",
       "      <td>178.375791</td>\n",
       "      <td>451.332504</td>\n",
       "      <td>100.946955</td>\n",
       "      <td>38.522861</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>473.000000</td>\n",
       "      <td>458.000000</td>\n",
       "      <td>383.000000</td>\n",
       "      <td>578.000000</td>\n",
       "      <td>model1</td>\n",
       "      <td>14</td>\n",
       "      <td>(0.0, 0.0, 0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>45</td>\n",
       "      <td>2015-12-31 06:00:00</td>\n",
       "      <td>181.883455</td>\n",
       "      <td>436.275814</td>\n",
       "      <td>105.677423</td>\n",
       "      <td>41.488344</td>\n",
       "      <td>174.565238</td>\n",
       "      <td>448.789051</td>\n",
       "      <td>100.450752</td>\n",
       "      <td>38.451472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>473.000000</td>\n",
       "      <td>458.000000</td>\n",
       "      <td>383.000000</td>\n",
       "      <td>578.000000</td>\n",
       "      <td>model1</td>\n",
       "      <td>14</td>\n",
       "      <td>(0.0, 0.0, 0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>45</td>\n",
       "      <td>2015-12-31 03:00:00</td>\n",
       "      <td>175.527648</td>\n",
       "      <td>450.987570</td>\n",
       "      <td>106.445780</td>\n",
       "      <td>36.081621</td>\n",
       "      <td>172.135354</td>\n",
       "      <td>448.508727</td>\n",
       "      <td>99.366501</td>\n",
       "      <td>38.539479</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>473.000000</td>\n",
       "      <td>458.000000</td>\n",
       "      <td>383.000000</td>\n",
       "      <td>578.000000</td>\n",
       "      <td>model1</td>\n",
       "      <td>14</td>\n",
       "      <td>(0.0, 0.0, 0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   machineID        dt_truncated  volt_rollingmean_3  rotate_rollingmean_3  \\\n",
       "0         45 2016-01-01 06:00:00          174.881727            527.816907   \n",
       "1         45 2016-01-01 03:00:00          188.406674            474.631787   \n",
       "2         45 2016-01-01 00:00:00          171.329008            454.871774   \n",
       "3         45 2015-12-31 21:00:00          187.832175            478.072922   \n",
       "4         45 2015-12-31 18:00:00          188.931361            465.157611   \n",
       "5         45 2015-12-31 15:00:00          187.519556            488.409741   \n",
       "6         45 2015-12-31 12:00:00          184.169519            476.258197   \n",
       "7         45 2015-12-31 09:00:00          198.755239            415.146541   \n",
       "8         45 2015-12-31 06:00:00          181.883455            436.275814   \n",
       "9         45 2015-12-31 03:00:00          175.527648            450.987570   \n",
       "\n",
       "   pressure_rollingmean_3  vibration_rollingmean_3  volt_rollingmean_24  \\\n",
       "0              117.225971                39.472147           185.926371   \n",
       "1              124.261901                38.869583           186.103373   \n",
       "2              123.029121                37.712346           184.493495   \n",
       "3              128.126653                38.659306           184.465271   \n",
       "4              115.048540                41.007536           182.153162   \n",
       "5               98.531106                40.679373           181.066678   \n",
       "6              103.798398                39.538776           179.502910   \n",
       "7              101.265224                41.802852           178.375791   \n",
       "8              105.677423                41.488344           174.565238   \n",
       "9              106.445780                36.081621           172.135354   \n",
       "\n",
       "   rotate_rollingmean_24  pressure_rollingmean_24  vibration_rollingmean_24  \\\n",
       "0             470.121966               113.564799                 39.936377   \n",
       "1             461.103049               112.467296                 39.969765   \n",
       "2             458.147521               110.240281                 39.621269   \n",
       "3             453.473419               107.234582                 39.799088   \n",
       "4             454.506948               103.728100                 39.916098   \n",
       "5             457.408755               101.431726                 38.982713   \n",
       "6             451.580197               101.653542                 38.605434   \n",
       "7             451.332504               100.946955                 38.522861   \n",
       "8             448.789051               100.450752                 38.451472   \n",
       "9             448.508727                99.366501                 38.539479   \n",
       "\n",
       "    ...     error5sum_rollingmean_24    comp1sum    comp2sum    comp3sum  \\\n",
       "0   ...                          0.0  474.000000  459.000000  384.000000   \n",
       "1   ...                          0.0  474.000000  459.000000  384.000000   \n",
       "2   ...                          0.0  473.666667  458.666667  383.666667   \n",
       "3   ...                          0.0  473.000000  458.000000  383.000000   \n",
       "4   ...                          0.0  473.000000  458.000000  383.000000   \n",
       "5   ...                          0.0  473.000000  458.000000  383.000000   \n",
       "6   ...                          0.0  473.000000  458.000000  383.000000   \n",
       "7   ...                          0.0  473.000000  458.000000  383.000000   \n",
       "8   ...                          0.0  473.000000  458.000000  383.000000   \n",
       "9   ...                          0.0  473.000000  458.000000  383.000000   \n",
       "\n",
       "     comp4sum   model  age    model_encoded  failure1  label_e  \n",
       "0  579.000000  model1   14  (0.0, 0.0, 0.0)       0.0      0.0  \n",
       "1  579.000000  model1   14  (0.0, 0.0, 0.0)       0.0      0.0  \n",
       "2  578.666667  model1   14  (0.0, 0.0, 0.0)       0.0      0.0  \n",
       "3  578.000000  model1   14  (0.0, 0.0, 0.0)       0.0      0.0  \n",
       "4  578.000000  model1   14  (0.0, 0.0, 0.0)       0.0      0.0  \n",
       "5  578.000000  model1   14  (0.0, 0.0, 0.0)       0.0      0.0  \n",
       "6  578.000000  model1   14  (0.0, 0.0, 0.0)       0.0      0.0  \n",
       "7  578.000000  model1   14  (0.0, 0.0, 0.0)       0.0      0.0  \n",
       "8  578.000000  model1   14  (0.0, 0.0, 0.0)       0.0      0.0  \n",
       "9  578.000000  model1   14  (0.0, 0.0, 0.0)       0.0      0.0  \n",
       "\n",
       "[10 rows x 32 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the previous created final dataset into the workspace\n",
    "# create a local path where we store results\n",
    "if not os.path.exists(FEATURES_LOCAL_DIRECT):\n",
    "    os.makedirs(FEATURES_LOCAL_DIRECT)\n",
    "    print('DONE creating a local directory!')\n",
    "\n",
    "# download the entire parquet result folder to local path for a new run \n",
    "for blob in my_service.list_blobs(CONTAINER_NAME):\n",
    "    if FEATURES_LOCAL_DIRECT in blob.name:\n",
    "        local_file = os.path.join(FEATURES_LOCAL_DIRECT, os.path.basename(blob.name))\n",
    "        my_service.get_blob_to_path(CONTAINER_NAME, blob.name, local_file)\n",
    "\n",
    "feat_data = spark.read.parquet(FEATURES_LOCAL_DIRECT)\n",
    "#data.persist()\n",
    "\n",
    "feat_data.limit(10).toPandas().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the Training/Testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with data that comes with time-stamps such as telemetry and errors as in this example, splitting of data into training, validation and test sets should be performed carefully to prevent overestimating the performance of the models. In predictive maintenance, the features are usually generated using laging aggregates and consecutive examples that fall into the same time window may have similar feature values in that window. If a random splitting of training and testing is used, it is possible for some portion of these similar examples that are in the same window to be selected for training and the other portion to leak into the testing data. Also, it is possible for training examples to be ahead of time than validation and testing examples when data is randomly split. However, predictive models should be trained on historical data and valiadted and tested on future data. Due to these problems, validation and testing based on random sampling may provide overly optimistic results. Since random sampling is not a viable approach here, cross validation methods that rely on random samples such as k-fold cross validation is not useful either.\n",
    "\n",
    "For predictive maintenance problems, a time-dependent spliting strategy is often a better approach to estimate performance which is done by validating and testing on examples that are later in time than the training examples. For a time-dependent split, a point in time is picked and model is trained on examples up to that point in time, and validated on the examples after that point assuming that the future data after the splitting point is not known. However, this effects the labelling of features falling into the labelling window right before the split as it is assumed that failure information is not known beyond the splitting cut-off. Due to that, those feature records can not be labeled and will not be used. This also prevents the leaking problem at the splitting point.\n",
    "\n",
    "Validation can be performed by picking different split points and examining the performance of the models trained on different time splits. In the following, we use a splitting points to train the model and look at the performances for the other split in the evaluation section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define list of input columns for downstream modeling - note model variable was removed as string was not supported\n",
    "input_features = [\n",
    "'volt_rollingmean_3',\n",
    "'rotate_rollingmean_3',\n",
    "'pressure_rollingmean_3',\n",
    "'vibration_rollingmean_3',\n",
    "'volt_rollingmean_24',\n",
    "'rotate_rollingmean_24',\n",
    "'pressure_rollingmean_24',\n",
    "'vibration_rollingmean_24',\n",
    "'volt_rollingstd_3',\n",
    "'rotate_rollingstd_3',\n",
    "'pressure_rollingstd_3',\n",
    "'vibration_rollingstd_3',\n",
    "'volt_rollingstd_24',\n",
    "'rotate_rollingstd_24',\n",
    "'pressure_rollingstd_24',\n",
    "'vibration_rollingstd_24',\n",
    "'error1sum_rollingmean_24',\n",
    "'error2sum_rollingmean_24',\n",
    "'error3sum_rollingmean_24',\n",
    "'error4sum_rollingmean_24',\n",
    "'error5sum_rollingmean_24',\n",
    "'comp1sum',\n",
    "'comp2sum',\n",
    "'comp3sum',\n",
    "'comp4sum',\n",
    "'age' #,\n",
    "#'model_encoded'    \n",
    "]\n",
    "\n",
    "label_var = ['label_e']\n",
    "key_cols =['machineID','dt_truncated']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# assemble features\n",
    "va = VectorAssembler(inputCols=(input_features), outputCol='features')\n",
    "feat_data = va.transform(feat_data).select('machineID','dt_truncated','label_e','features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set maxCategories so features with > 10 distinct values are treated as continuous.\n",
    "featureIndexer = VectorIndexer(inputCol=\"features\", \n",
    "                               outputCol=\"indexedFeatures\", \n",
    "                               maxCategories=10).fit(feat_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit on whole dataset to include all labels in index\n",
    "labelIndexer = StringIndexer(inputCol=\"label_e\", outputCol=\"indexedLabel\").fit(feat_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2174000\n",
      "747000\n"
     ]
    }
   ],
   "source": [
    "# split the data into train/test based on date\n",
    "training = feat_data.filter(feat_data.dt_truncated > \"2015-01-01\").filter(feat_data.dt_truncated < \"2015-09-30\")\n",
    "testing = feat_data.filter(feat_data.dt_truncated > \"2015-09-30\")\n",
    "\n",
    "print(training.count())\n",
    "print(testing.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification models\n",
    "\n",
    "In this notebook we will compare two models namely Random Forest Classifier and Decision Tree Classifier. The user can add in more models and compare each model with varying hyperparameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train a RandomForest model.\n",
    "rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", numTrees=100)\n",
    "\n",
    "# chain indexers and forest in a Pipeline\n",
    "pipeline_rf = Pipeline(stages=[labelIndexer, featureIndexer, rf])\n",
    "\n",
    "# train model.  This also runs the indexers.\n",
    "model_rf = pipeline_rf.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+------+\n",
      "|indexedLabel|prediction| count|\n",
      "+------------+----------+------+\n",
      "|         2.0|       0.0|   283|\n",
      "|         1.0|       1.0|  4701|\n",
      "|         0.0|       1.0|     3|\n",
      "|         2.0|       2.0|  3346|\n",
      "|         1.0|       0.0|     1|\n",
      "|         4.0|       4.0|    28|\n",
      "|         2.0|       1.0|     1|\n",
      "|         0.0|       0.0|734483|\n",
      "|         0.0|       2.0|    88|\n",
      "|         4.0|       0.0|  1695|\n",
      "|         3.0|       3.0|  2106|\n",
      "|         0.0|       3.0|   228|\n",
      "|         3.0|       0.0|    37|\n",
      "+------------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# make predictions.\n",
    "predictions_rf = model_rf.transform(testing)\n",
    "predictions_rf.groupby('indexedLabel', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictionAndLabels = predictions_rf.select(\"indexedLabel\", \"prediction\").rdd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In predictive maintenance, machine failures are usually rare occurrences in the lifetime of the assets compared to normal operation. This causes an imbalance in the label distribution which usually causes poor performance as algorithms tend to classify majority class examples better at the expense of minority class examples as the total misclassification error is much improved when majority class is labeled correctly. This causes low recall rates although accuracy can be high and becomes a larger problem when the cost of false alarms to the business is very high. To help with this problem, sampling techniques such as oversampling of the minority examples are usually used along with more sophisticated techniques which are not covered in this notebook.\n",
    "\n",
    "Also, due to the class imbalance problem, it is important to look at evaluation metrics other than accuracy alone and compare those metrics to the baseline metrics which are computed when random chance is used to make predictions rather than a machine learning model. The comparison will bring out the value and benefits of using a machine learning model better.\n",
    "\n",
    "In the following, we compute weighted precision/recall, F1 score along with the accuracy metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.996873\n"
     ]
    }
   ],
   "source": [
    "# select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\")\n",
    "print(\"Accuracy = %g\" % evaluator.evaluate(predictions_rf, {evaluator.metricName: \"accuracy\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Precision = 0.996897\n"
     ]
    }
   ],
   "source": [
    "print(\"Weighted Precision = %g\" % evaluator.evaluate(predictions_rf, {evaluator.metricName: \"weightedPrecision\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Recall = 0.996873\n"
     ]
    }
   ],
   "source": [
    "print(\"Weighted Recall = %g\" % evaluator.evaluate(predictions_rf, {evaluator.metricName: \"weightedRecall\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 = 0.995777\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 = %g\" % evaluator.evaluate(predictions_rf, {evaluator.metricName: \"f1\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train a DT model.\n",
    "dt = DecisionTreeClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\")\n",
    "\n",
    "# chain indexers and forest in a Pipeline\n",
    "pipeline_dt = Pipeline(stages=[labelIndexer, featureIndexer, dt])\n",
    "\n",
    "# train model.  This also runs the indexers.\n",
    "model_dt = pipeline_dt.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions.\n",
    "predictions_dt = model_dt.transform(testing)\n",
    "predictions_dt.groupby('indexedLabel', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictionAndLabels = predictions_dt.select(\"indexedLabel\", \"prediction\").rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\")\n",
    "print(\"Accuracy = %g\" % evaluator.evaluate(predictions_dt, {evaluator.metricName: \"accuracy\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Weighted Precision = %g\" % evaluator.evaluate(predictions_dt, {evaluator.metricName: \"weightedPrecision\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Weighted Recall = %g\" % evaluator.evaluate(predictions_dt, {evaluator.metricName: \"weightedRecall\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F1 = %g\" % evaluator.evaluate(predictions_dt, {evaluator.metricName: \"f1\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In the next notebook Code\\operationalization.ipynb Jupyter notebook we will learn how to create the functions needed to operationalize and deploy any model to get realtime predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model_rf.write().overwrite().save(os.environ['AZUREML_NATIVE_SHARE_DIRECTORY']+'pdmrfull.model')\n",
    "print(\"Model saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Hack2 docker",
   "language": "python",
   "name": "hack2_docker"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

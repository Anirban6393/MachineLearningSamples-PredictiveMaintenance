{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Feature Engineering\n",
    "\n",
    "In this notebook, we will load the data stored in Azure Blob containers in the previous **Data Ingestion** notebook, and create the features used in our predictive maintenance machine learning solution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup our environment by importing required libraries\n",
    "import os\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import datediff\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "from azure.storage.blob import BlockBlobService\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from Azure Blob storage container\n",
    "\n",
    "We have previously downloaded and stored the following data in an Azure blob storage container:\n",
    "\n",
    "\n",
    "  * Machines: Features differentiating each machine. For example age and model.\n",
    "  * Error: The log of non-critical errors. These errors may still indicate an impending component failure.\n",
    "  * Maint: Machine maintenance history detailing component replacement or regular maintenance activities withe the date of replacement.\n",
    "  * Telemetry: The operating conditions of a machine e.g. data collected from sensors.\n",
    "  * Failure history: The failure history of a machine or component within the machine.\n",
    "\n",
    "We'll load these files from blob, and create our analysis data set here. We'll write this data set back into a new blob container to use in our model building and evaluation notebook later. \n",
    "\n",
    "Since the Azure Blob storage account name and account key are not passed between notebooks, you'll need to provide those here again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Enter your Azure blob storage details here \n",
    "ACCOUNT_NAME = \"pdmamlworkbench\"   ## \"<your blob storage account name>\"\n",
    "\n",
    "# You can find the account key under the _Access Keys_ link in the \n",
    "# [Azure Portal](portal.azure.com) page for your Azure storage container.\n",
    "ACCOUNT_KEY = \"O5uLzNKX7o+ZHFXtHDyS87SIev9QHlkdX2IhIbxYwhRo7sA9zp45HOOFFttUp4r0LyWCcLQ0cCA7l+e8Ct3Yew==\" ## \"<account key>\"\n",
    "\n",
    "#-------------------------------------------------------------------------------------------\n",
    "# The data from the Data Aquisition note book is stored in the dataingestion container.\n",
    "CONTAINER_NAME = \"dataingestion\"\n",
    "\n",
    "# Connect to your blob service     \n",
    "my_service = BlockBlobService(account_name=ACCOUNT_NAME, account_key=ACCOUNT_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machines data set\n",
    "\n",
    "Load the machines data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>machineID</th>\n",
       "      <th>model</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>model2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>model4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>model3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>model3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>model2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>model3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>model4</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>model3</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>model1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>model1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>model4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>model2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>model3</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>model4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>model4</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>model3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>model4</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>model4</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>model4</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>model2</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    machineID   model  age\n",
       "0           1  model2   18\n",
       "1           2  model4    7\n",
       "2           3  model3    8\n",
       "3           4  model3    7\n",
       "4           5  model2    2\n",
       "5           6  model3    7\n",
       "6           7  model4   20\n",
       "7           8  model3   16\n",
       "8           9  model1    7\n",
       "9          10  model1   10\n",
       "10         11  model4    6\n",
       "11         12  model2    9\n",
       "12         13  model3   15\n",
       "13         14  model4    1\n",
       "14         15  model4   14\n",
       "15         16  model3    3\n",
       "16         17  model4   14\n",
       "17         18  model4   15\n",
       "18         19  model4   17\n",
       "19         20  model2   16"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download the entire parquet result folder to local path for a new run \n",
    "LOCAL_DIRECT = 'dataingestion_machines_result.parquet'\n",
    "if not os.path.exists(LOCAL_DIRECT):\n",
    "    os.makedirs(LOCAL_DIRECT)\n",
    "    print('DONE creating a local directory!')\n",
    "\n",
    "for blob in my_service.list_blobs(CONTAINER_NAME):\n",
    "    if 'machines_files.parquet' in blob.name:\n",
    "        local_file = os.path.join(LOCAL_DIRECT, os.path.basename(blob.name))\n",
    "        my_service.get_blob_to_path(CONTAINER_NAME, blob.name, local_file)\n",
    "\n",
    "machines = spark.read.parquet(LOCAL_DIRECT)\n",
    "\n",
    "print(machines.count())\n",
    "machines.toPandas().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11967\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>machineID</th>\n",
       "      <th>errorID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-04-08 19:00:00</td>\n",
       "      <td>251</td>\n",
       "      <td>error3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-06-09 06:00:00</td>\n",
       "      <td>251</td>\n",
       "      <td>error1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-08-08 06:00:00</td>\n",
       "      <td>251</td>\n",
       "      <td>error4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-09-07 06:00:00</td>\n",
       "      <td>251</td>\n",
       "      <td>error2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-09-07 06:00:00</td>\n",
       "      <td>251</td>\n",
       "      <td>error3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015-09-22 06:00:00</td>\n",
       "      <td>251</td>\n",
       "      <td>error1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2015-09-22 06:00:00</td>\n",
       "      <td>251</td>\n",
       "      <td>error4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015-12-06 06:00:00</td>\n",
       "      <td>251</td>\n",
       "      <td>error4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2015-01-03 06:00:00</td>\n",
       "      <td>252</td>\n",
       "      <td>error1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2015-01-20 12:00:00</td>\n",
       "      <td>252</td>\n",
       "      <td>error3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2015-03-04 06:00:00</td>\n",
       "      <td>252</td>\n",
       "      <td>error2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2015-03-04 06:00:00</td>\n",
       "      <td>252</td>\n",
       "      <td>error3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2015-04-18 06:00:00</td>\n",
       "      <td>252</td>\n",
       "      <td>error2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2015-04-18 06:00:00</td>\n",
       "      <td>252</td>\n",
       "      <td>error3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2015-06-05 03:00:00</td>\n",
       "      <td>252</td>\n",
       "      <td>error3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2015-06-17 06:00:00</td>\n",
       "      <td>252</td>\n",
       "      <td>error1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2015-10-30 06:00:00</td>\n",
       "      <td>252</td>\n",
       "      <td>error2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2015-10-30 06:00:00</td>\n",
       "      <td>252</td>\n",
       "      <td>error3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2015-12-26 05:00:00</td>\n",
       "      <td>252</td>\n",
       "      <td>error1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2015-01-03 10:00:00</td>\n",
       "      <td>253</td>\n",
       "      <td>error1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               datetime  machineID errorID\n",
       "0   2015-04-08 19:00:00        251  error3\n",
       "1   2015-06-09 06:00:00        251  error1\n",
       "2   2015-08-08 06:00:00        251  error4\n",
       "3   2015-09-07 06:00:00        251  error2\n",
       "4   2015-09-07 06:00:00        251  error3\n",
       "5   2015-09-22 06:00:00        251  error1\n",
       "6   2015-09-22 06:00:00        251  error4\n",
       "7   2015-12-06 06:00:00        251  error4\n",
       "8   2015-01-03 06:00:00        252  error1\n",
       "9   2015-01-20 12:00:00        252  error3\n",
       "10  2015-03-04 06:00:00        252  error2\n",
       "11  2015-03-04 06:00:00        252  error3\n",
       "12  2015-04-18 06:00:00        252  error2\n",
       "13  2015-04-18 06:00:00        252  error3\n",
       "14  2015-06-05 03:00:00        252  error3\n",
       "15  2015-06-17 06:00:00        252  error1\n",
       "16  2015-10-30 06:00:00        252  error2\n",
       "17  2015-10-30 06:00:00        252  error3\n",
       "18  2015-12-26 05:00:00        252  error1\n",
       "19  2015-01-03 10:00:00        253  error1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the previous created final dataset into the workspace\n",
    "\n",
    "# create a local path where to store the results later.\n",
    "LOCAL_DIRECT = 'dataingestion_err_result.parquet'\n",
    "if not os.path.exists(LOCAL_DIRECT):\n",
    "    os.makedirs(LOCAL_DIRECT)\n",
    "    print('DONE creating a local directory!')\n",
    "\n",
    "# download the entire parquet result folder to local path for a new run \n",
    "for blob in my_service.list_blobs(CONTAINER_NAME):\n",
    "    if 'errors_files.parquet' in blob.name:\n",
    "        local_file = os.path.join(LOCAL_DIRECT, os.path.basename(blob.name))\n",
    "        my_service.get_blob_to_path(CONTAINER_NAME, blob.name, local_file)\n",
    "\n",
    "errors = spark.read.parquet(LOCAL_DIRECT)\n",
    "\n",
    "print(errors.count())\n",
    "errors.toPandas().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maintenance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32592\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>machineID</th>\n",
       "      <th>comp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-04 06:00:00</td>\n",
       "      <td>252</td>\n",
       "      <td>comp1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-19 06:00:00</td>\n",
       "      <td>252</td>\n",
       "      <td>comp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-02-18 06:00:00</td>\n",
       "      <td>252</td>\n",
       "      <td>comp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-03-05 06:00:00</td>\n",
       "      <td>252</td>\n",
       "      <td>comp2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-03-20 06:00:00</td>\n",
       "      <td>252</td>\n",
       "      <td>comp1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015-04-04 06:00:00</td>\n",
       "      <td>252</td>\n",
       "      <td>comp1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2015-04-19 06:00:00</td>\n",
       "      <td>252</td>\n",
       "      <td>comp2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015-06-03 06:00:00</td>\n",
       "      <td>252</td>\n",
       "      <td>comp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2015-06-18 06:00:00</td>\n",
       "      <td>252</td>\n",
       "      <td>comp1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2015-07-18 06:00:00</td>\n",
       "      <td>252</td>\n",
       "      <td>comp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2015-08-02 06:00:00</td>\n",
       "      <td>252</td>\n",
       "      <td>comp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2015-08-17 06:00:00</td>\n",
       "      <td>252</td>\n",
       "      <td>comp2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2015-09-16 06:00:00</td>\n",
       "      <td>252</td>\n",
       "      <td>comp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2015-10-01 06:00:00</td>\n",
       "      <td>252</td>\n",
       "      <td>comp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2015-10-16 06:00:00</td>\n",
       "      <td>252</td>\n",
       "      <td>comp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2015-10-16 06:00:00</td>\n",
       "      <td>252</td>\n",
       "      <td>comp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2015-10-31 06:00:00</td>\n",
       "      <td>252</td>\n",
       "      <td>comp2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2015-11-15 06:00:00</td>\n",
       "      <td>252</td>\n",
       "      <td>comp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2015-11-30 06:00:00</td>\n",
       "      <td>252</td>\n",
       "      <td>comp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2015-12-15 06:00:00</td>\n",
       "      <td>252</td>\n",
       "      <td>comp4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               datetime  machineID   comp\n",
       "0   2015-01-04 06:00:00        252  comp1\n",
       "1   2015-01-19 06:00:00        252  comp4\n",
       "2   2015-02-18 06:00:00        252  comp3\n",
       "3   2015-03-05 06:00:00        252  comp2\n",
       "4   2015-03-20 06:00:00        252  comp1\n",
       "5   2015-04-04 06:00:00        252  comp1\n",
       "6   2015-04-19 06:00:00        252  comp2\n",
       "7   2015-06-03 06:00:00        252  comp4\n",
       "8   2015-06-18 06:00:00        252  comp1\n",
       "9   2015-07-18 06:00:00        252  comp4\n",
       "10  2015-08-02 06:00:00        252  comp4\n",
       "11  2015-08-17 06:00:00        252  comp2\n",
       "12  2015-09-16 06:00:00        252  comp3\n",
       "13  2015-10-01 06:00:00        252  comp3\n",
       "14  2015-10-16 06:00:00        252  comp4\n",
       "15  2015-10-16 06:00:00        252  comp3\n",
       "16  2015-10-31 06:00:00        252  comp2\n",
       "17  2015-11-15 06:00:00        252  comp4\n",
       "18  2015-11-30 06:00:00        252  comp3\n",
       "19  2015-12-15 06:00:00        252  comp4"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the previous created final dataset into the workspace\n",
    "# create a local path where to store the results later.\n",
    "LOCAL_DIRECT = 'dataingestion_maint_result.parquet'\n",
    "if not os.path.exists(LOCAL_DIRECT):\n",
    "    os.makedirs(LOCAL_DIRECT)\n",
    "    print('DONE creating a local directory!')\n",
    "\n",
    "# download the entire parquet result folder to local path for a new run \n",
    "for blob in my_service.list_blobs(CONTAINER_NAME):\n",
    "    if 'maint_files.parquet' in blob.name:\n",
    "        local_file = os.path.join(LOCAL_DIRECT, os.path.basename(blob.name))\n",
    "        my_service.get_blob_to_path(CONTAINER_NAME, blob.name, local_file)\n",
    "\n",
    "maint = spark.read.parquet(LOCAL_DIRECT)\n",
    "\n",
    "print(maint.count())\n",
    "maint.toPandas().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Telemetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8761000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>machineID</th>\n",
       "      <th>volt</th>\n",
       "      <th>rotate</th>\n",
       "      <th>pressure</th>\n",
       "      <th>vibration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1420711200000000000</td>\n",
       "      <td>501</td>\n",
       "      <td>165.775142</td>\n",
       "      <td>456.014484</td>\n",
       "      <td>96.779707</td>\n",
       "      <td>40.200315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1420714800000000000</td>\n",
       "      <td>501</td>\n",
       "      <td>167.694494</td>\n",
       "      <td>415.396525</td>\n",
       "      <td>106.346838</td>\n",
       "      <td>39.454320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1420718400000000000</td>\n",
       "      <td>501</td>\n",
       "      <td>149.286911</td>\n",
       "      <td>549.794168</td>\n",
       "      <td>110.590462</td>\n",
       "      <td>46.649346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1420722000000000000</td>\n",
       "      <td>501</td>\n",
       "      <td>164.315444</td>\n",
       "      <td>485.343432</td>\n",
       "      <td>102.644426</td>\n",
       "      <td>38.615502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1420725600000000000</td>\n",
       "      <td>501</td>\n",
       "      <td>178.789891</td>\n",
       "      <td>447.830204</td>\n",
       "      <td>100.238279</td>\n",
       "      <td>36.380291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1420729200000000000</td>\n",
       "      <td>501</td>\n",
       "      <td>137.114258</td>\n",
       "      <td>544.049900</td>\n",
       "      <td>114.228800</td>\n",
       "      <td>41.865415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1420732800000000000</td>\n",
       "      <td>501</td>\n",
       "      <td>186.462256</td>\n",
       "      <td>453.722096</td>\n",
       "      <td>89.747835</td>\n",
       "      <td>38.535097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1420736400000000000</td>\n",
       "      <td>501</td>\n",
       "      <td>194.811026</td>\n",
       "      <td>436.807652</td>\n",
       "      <td>86.598670</td>\n",
       "      <td>30.765251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1420740000000000000</td>\n",
       "      <td>501</td>\n",
       "      <td>149.091834</td>\n",
       "      <td>440.036746</td>\n",
       "      <td>93.430204</td>\n",
       "      <td>46.478393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1420743600000000000</td>\n",
       "      <td>501</td>\n",
       "      <td>175.940093</td>\n",
       "      <td>457.777419</td>\n",
       "      <td>103.471539</td>\n",
       "      <td>33.161014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1420747200000000000</td>\n",
       "      <td>501</td>\n",
       "      <td>186.622016</td>\n",
       "      <td>459.618614</td>\n",
       "      <td>86.755194</td>\n",
       "      <td>43.155218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1420750800000000000</td>\n",
       "      <td>501</td>\n",
       "      <td>188.176644</td>\n",
       "      <td>504.955081</td>\n",
       "      <td>74.248426</td>\n",
       "      <td>44.928776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1420754400000000000</td>\n",
       "      <td>501</td>\n",
       "      <td>170.043078</td>\n",
       "      <td>392.203024</td>\n",
       "      <td>112.208908</td>\n",
       "      <td>50.774969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1420758000000000000</td>\n",
       "      <td>501</td>\n",
       "      <td>141.979952</td>\n",
       "      <td>456.166550</td>\n",
       "      <td>110.224106</td>\n",
       "      <td>43.269971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1420761600000000000</td>\n",
       "      <td>501</td>\n",
       "      <td>170.749771</td>\n",
       "      <td>449.162982</td>\n",
       "      <td>96.670764</td>\n",
       "      <td>42.250168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1420765200000000000</td>\n",
       "      <td>501</td>\n",
       "      <td>154.185573</td>\n",
       "      <td>432.810488</td>\n",
       "      <td>87.158285</td>\n",
       "      <td>41.352790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1420768800000000000</td>\n",
       "      <td>501</td>\n",
       "      <td>147.222624</td>\n",
       "      <td>515.094912</td>\n",
       "      <td>84.783004</td>\n",
       "      <td>34.759178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1420772400000000000</td>\n",
       "      <td>501</td>\n",
       "      <td>175.318635</td>\n",
       "      <td>474.274774</td>\n",
       "      <td>92.196507</td>\n",
       "      <td>47.713774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1420776000000000000</td>\n",
       "      <td>501</td>\n",
       "      <td>182.782738</td>\n",
       "      <td>447.707948</td>\n",
       "      <td>94.309360</td>\n",
       "      <td>38.205513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1420779600000000000</td>\n",
       "      <td>501</td>\n",
       "      <td>202.876704</td>\n",
       "      <td>448.049725</td>\n",
       "      <td>103.353824</td>\n",
       "      <td>43.012794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               datetime  machineID        volt      rotate    pressure  \\\n",
       "0   1420711200000000000        501  165.775142  456.014484   96.779707   \n",
       "1   1420714800000000000        501  167.694494  415.396525  106.346838   \n",
       "2   1420718400000000000        501  149.286911  549.794168  110.590462   \n",
       "3   1420722000000000000        501  164.315444  485.343432  102.644426   \n",
       "4   1420725600000000000        501  178.789891  447.830204  100.238279   \n",
       "5   1420729200000000000        501  137.114258  544.049900  114.228800   \n",
       "6   1420732800000000000        501  186.462256  453.722096   89.747835   \n",
       "7   1420736400000000000        501  194.811026  436.807652   86.598670   \n",
       "8   1420740000000000000        501  149.091834  440.036746   93.430204   \n",
       "9   1420743600000000000        501  175.940093  457.777419  103.471539   \n",
       "10  1420747200000000000        501  186.622016  459.618614   86.755194   \n",
       "11  1420750800000000000        501  188.176644  504.955081   74.248426   \n",
       "12  1420754400000000000        501  170.043078  392.203024  112.208908   \n",
       "13  1420758000000000000        501  141.979952  456.166550  110.224106   \n",
       "14  1420761600000000000        501  170.749771  449.162982   96.670764   \n",
       "15  1420765200000000000        501  154.185573  432.810488   87.158285   \n",
       "16  1420768800000000000        501  147.222624  515.094912   84.783004   \n",
       "17  1420772400000000000        501  175.318635  474.274774   92.196507   \n",
       "18  1420776000000000000        501  182.782738  447.707948   94.309360   \n",
       "19  1420779600000000000        501  202.876704  448.049725  103.353824   \n",
       "\n",
       "    vibration  \n",
       "0   40.200315  \n",
       "1   39.454320  \n",
       "2   46.649346  \n",
       "3   38.615502  \n",
       "4   36.380291  \n",
       "5   41.865415  \n",
       "6   38.535097  \n",
       "7   30.765251  \n",
       "8   46.478393  \n",
       "9   33.161014  \n",
       "10  43.155218  \n",
       "11  44.928776  \n",
       "12  50.774969  \n",
       "13  43.269971  \n",
       "14  42.250168  \n",
       "15  41.352790  \n",
       "16  34.759178  \n",
       "17  47.713774  \n",
       "18  38.205513  \n",
       "19  43.012794  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# download the entire parquet result folder to local path for a new run \n",
    "# create a local path where to store the results later.\n",
    "LOCAL_DIRECT = 'dataingestion_tel_result.parquet'\n",
    "if not os.path.exists(LOCAL_DIRECT):\n",
    "    os.makedirs(LOCAL_DIRECT)\n",
    "    print('DONE creating a local directory!')\n",
    "    \n",
    "for blob in my_service.list_blobs(CONTAINER_NAME):\n",
    "    if 'telemetry_files.parquet' in blob.name:\n",
    "        local_file = os.path.join(LOCAL_DIRECT, os.path.basename(blob.name))\n",
    "        my_service.get_blob_to_path(CONTAINER_NAME, blob.name, local_file)\n",
    "\n",
    "telemetry = spark.read.parquet(LOCAL_DIRECT)\n",
    "\n",
    "print(telemetry.count())\n",
    "telemetry.toPandas().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6726\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>machineID</th>\n",
       "      <th>failure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-09-18 06:00:00</td>\n",
       "      <td>453</td>\n",
       "      <td>comp2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-12-17 06:00:00</td>\n",
       "      <td>453</td>\n",
       "      <td>comp2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-03-27 06:00:00</td>\n",
       "      <td>454</td>\n",
       "      <td>comp2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-08-24 06:00:00</td>\n",
       "      <td>454</td>\n",
       "      <td>comp2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-09-23 06:00:00</td>\n",
       "      <td>454</td>\n",
       "      <td>comp1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015-11-07 06:00:00</td>\n",
       "      <td>454</td>\n",
       "      <td>comp1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2015-03-14 06:00:00</td>\n",
       "      <td>455</td>\n",
       "      <td>comp1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015-12-24 06:00:00</td>\n",
       "      <td>455</td>\n",
       "      <td>comp1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2015-07-01 06:00:00</td>\n",
       "      <td>456</td>\n",
       "      <td>comp1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2015-11-28 06:00:00</td>\n",
       "      <td>456</td>\n",
       "      <td>comp1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2015-01-10 06:00:00</td>\n",
       "      <td>457</td>\n",
       "      <td>comp1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2015-02-24 06:00:00</td>\n",
       "      <td>457</td>\n",
       "      <td>comp2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2015-03-26 06:00:00</td>\n",
       "      <td>457</td>\n",
       "      <td>comp2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2015-04-25 06:00:00</td>\n",
       "      <td>457</td>\n",
       "      <td>comp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2015-07-09 06:00:00</td>\n",
       "      <td>457</td>\n",
       "      <td>comp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2015-08-08 06:00:00</td>\n",
       "      <td>457</td>\n",
       "      <td>comp2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2015-09-22 06:00:00</td>\n",
       "      <td>457</td>\n",
       "      <td>comp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2015-03-11 06:00:00</td>\n",
       "      <td>458</td>\n",
       "      <td>comp1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2015-10-22 06:00:00</td>\n",
       "      <td>458</td>\n",
       "      <td>comp1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2015-12-06 06:00:00</td>\n",
       "      <td>458</td>\n",
       "      <td>comp2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               datetime  machineID failure\n",
       "0   2015-09-18 06:00:00        453   comp2\n",
       "1   2015-12-17 06:00:00        453   comp2\n",
       "2   2015-03-27 06:00:00        454   comp2\n",
       "3   2015-08-24 06:00:00        454   comp2\n",
       "4   2015-09-23 06:00:00        454   comp1\n",
       "5   2015-11-07 06:00:00        454   comp1\n",
       "6   2015-03-14 06:00:00        455   comp1\n",
       "7   2015-12-24 06:00:00        455   comp1\n",
       "8   2015-07-01 06:00:00        456   comp1\n",
       "9   2015-11-28 06:00:00        456   comp1\n",
       "10  2015-01-10 06:00:00        457   comp1\n",
       "11  2015-02-24 06:00:00        457   comp2\n",
       "12  2015-03-26 06:00:00        457   comp2\n",
       "13  2015-04-25 06:00:00        457   comp4\n",
       "14  2015-07-09 06:00:00        457   comp4\n",
       "15  2015-08-08 06:00:00        457   comp2\n",
       "16  2015-09-22 06:00:00        457   comp4\n",
       "17  2015-03-11 06:00:00        458   comp1\n",
       "18  2015-10-22 06:00:00        458   comp1\n",
       "19  2015-12-06 06:00:00        458   comp2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the previous created final dataset into the workspace\n",
    "# create a local path where to store the results later.\n",
    "LOCAL_DIRECT = 'dataingestion_fail_result.parquet'\n",
    "if not os.path.exists(LOCAL_DIRECT):\n",
    "    os.makedirs(LOCAL_DIRECT)\n",
    "    print('DONE creating a local directory!')\n",
    "\n",
    "# download the entire parquet result folder to local path for a new run \n",
    "for blob in my_service.list_blobs(CONTAINER_NAME):\n",
    "    if 'failure_files.parquet' in blob.name:\n",
    "        local_file = os.path.join(LOCAL_DIRECT, os.path.basename(blob.name))\n",
    "        my_service.get_blob_to_path(CONTAINER_NAME, blob.name, local_file)\n",
    "\n",
    "failures = spark.read.parquet(LOCAL_DIRECT)\n",
    "\n",
    "print(failures.count())\n",
    "failures.toPandas().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lag features from Telemetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "rolling_features = ['volt','rotate', 'pressure', 'vibration']\n",
    "               \n",
    "# lag window 3hrs, 24 hrs\n",
    "lags = [3,24]\n",
    "\n",
    "print(len(rolling_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'F' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-7449b1e481ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mwSpec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartitionBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'machineID'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morderBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'datetime'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrowsBetween\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlag_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcol_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrolling_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mtel_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtel_mean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_rollingmean_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlag_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwSpec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Lag = %d, Column = %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlag_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'F' is not defined"
     ]
    }
   ],
   "source": [
    "# rolling mean\n",
    "tel_mean = telemetry\n",
    "\n",
    "for lag_n in lags:\n",
    "    wSpec = Window.partitionBy('machineID').orderBy('datetime').rowsBetween(1-lag_n, 0)\n",
    "    for col_name in rolling_features:\n",
    "        tel_mean = tel_mean.withColumn(col_name+'_rollingmean_'+str(lag_n), F.avg(col(col_name)).over(wSpec))\n",
    "        print(\"Lag = %d, Column = %s\" % (lag_n, col_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rolling std\n",
    "tel_sd = telemetry\n",
    "\n",
    "for lag_n in lags:\n",
    "    wSpec = Window.partitionBy('machineID').orderBy('datetime').rowsBetween(1-lag_n, 0)\n",
    "    for col_name in rolling_features:\n",
    "        tel_sd = tel_sd.withColumn(col_name+'_rollingstd_'+str(lag_n), F.stddev(col(col_name)).over(wSpec))\n",
    "        print(\"Lag = %d, Column = %s\" % (lag_n, col_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tel_mean.where((col(\"machineID\") == 1)).show(5)\n",
    "#tel_sd.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resample telemetry time variable to every 3 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tel_mean rolling mean\n",
    "# 3 hours = 10800 seconds  \n",
    "time_val = 10800\n",
    "dt_truncated = ((round(unix_timestamp(col(\"datetime\")) / time_val) * time_val)\n",
    "    .cast(\"timestamp\"))\n",
    "\n",
    "tel_mean_resampled = tel_mean.withColumn(\"dt_truncated\", dt_truncated).drop('volt', 'rotate', 'pressure', 'vibration')\n",
    "tel_mean_resampled.where((col(\"machineID\") == 1)).show(5)\n",
    "\n",
    "tel_mean_resampled1 = (tel_mean_resampled.groupBy(\"machineID\",\"dt_truncated\")\n",
    "                               .agg(F.mean('volt_rollingmean_3').alias('volt_rollingmean_3'),\n",
    "                                    F.mean('rotate_rollingmean_3').alias('rotate_rollingmean_3'), \n",
    "                                    F.mean('pressure_rollingmean_3').alias('pressure_rollingmean_3'), \n",
    "                                    F.mean('vibration_rollingmean_3').alias('vibration_rollingmean_3'), \n",
    "                                    F.mean('volt_rollingmean_24').alias('volt_rollingmean_24'),\n",
    "                                    F.mean('rotate_rollingmean_24').alias('rotate_rollingmean_24'), \n",
    "                                    F.mean('pressure_rollingmean_24').alias('pressure_rollingmean_24'), \n",
    "                                    F.mean('vibration_rollingmean_24').alias('vibration_rollingmean_24')))\n",
    "tel_mean_resampled1.where((col(\"machineID\") == 1)).show(5)\n",
    "tel_mean_resampled1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tel_sd rolling sd\n",
    "dt_truncated = ((round(unix_timestamp(col(\"datetime\")) / time_val) * time_val)\n",
    "    .cast(\"timestamp\"))\n",
    "\n",
    "tel_sd_resampled = (tel_sd.withColumn(\"dt_truncated\", dt_truncated).drop('volt', 'rotate', 'pressure', 'vibration')\n",
    "                        .fillna(0))\n",
    "tel_sd_resampled.show(5)\n",
    "\n",
    "tel_sd_resampled1 = (tel_sd_resampled.groupBy(\"machineID\",\"dt_truncated\")\n",
    "                               .agg(F.mean('volt_rollingstd_3').alias('volt_rollingstd_3'),\n",
    "                                    F.mean('rotate_rollingstd_3').alias('rotate_rollingstd_3'), \n",
    "                                    F.mean('pressure_rollingstd_3').alias('pressure_rollingstd_3'), \n",
    "                                    F.mean('vibration_rollingstd_3').alias('vibration_rollingstd_3'), \n",
    "                                    F.mean('volt_rollingstd_24').alias('volt_rollingstd_24'),\n",
    "                                    F.mean('rotate_rollingstd_24').alias('rotate_rollingstd_24'), \n",
    "                                    F.mean('pressure_rollingstd_24').alias('pressure_rollingstd_24'), \n",
    "                                    F.mean('vibration_rollingstd_24').alias('vibration_rollingstd_24')))\n",
    "tel_sd_resampled1.show(5)\n",
    "tel_sd_resampled1.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lag features from Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "errors.show(5)\n",
    "errors.toPandas()['errorID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a column for each errorID \n",
    "error1 = errors.groupBy(\"machineID\",\"datetime\",\"errorID\").pivot('errorID').agg(F.count('machineID').alias('dummy'))\n",
    "\n",
    "error1.show(5, False)\n",
    "error1.count(), len(error1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove the column called errorID and fill in missing values\n",
    "error2 = error1.drop('errorID').fillna(0)\n",
    "error2.show(5, False)\n",
    "error2.count(), len(error2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combine errors for a given machine in a given hour\n",
    "error3 = (error2.groupBy(\"machineID\",\"datetime\")\n",
    "                .agg(F.sum('error1').alias('error1sum'), \n",
    "                     F.sum('error2').alias('error2sum'), \n",
    "                     F.sum('error3').alias('error3sum'), \n",
    "                     F.sum('error4').alias('error4sum'), \n",
    "                     F.sum('error5').alias('error5sum')))\n",
    "\n",
    "error3.show(5, False)\n",
    "error3.count(), len(error3.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# join the telemetry data with errors\n",
    "error_count = (telemetry.join(error3, ((telemetry['machineID'] == error3['machineID']) \n",
    "                                  & (telemetry['datetime'] == error3['datetime'])), \"left\")\n",
    "               .drop('volt', 'rotate', 'pressure', 'vibration').drop(error3.machineID).drop(error3.datetime))\n",
    "\n",
    "error_count.show(5, False)\n",
    "error_count.count(), len(error_count.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fill in missing value\n",
    "error_count1 = error_count.fillna(0)\n",
    "\n",
    "error_count1.show(5, False)\n",
    "error_count1.count(), len(error_count1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check the data statistics\n",
    "error_count1.describe(\"error1sum\",\"error2sum\", \"error3sum\", \"error4sum\", \"error5sum\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rolling_features1 = ['error1sum','error2sum', 'error3sum', 'error4sum', 'error5sum']\n",
    "               \n",
    "# lag window 24 hrs\n",
    "lags = [24]\n",
    "\n",
    "print(len(rolling_features1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rolling mean\n",
    "err_mean = error_count1\n",
    "\n",
    "for lag_n in lags:\n",
    "    wSpec = Window.partitionBy('machineID').orderBy('datetime').rowsBetween(1-lag_n, 0)\n",
    "    for col_name in rolling_features1:\n",
    "        err_mean = err_mean.withColumn(col_name+'_rollingmean_'+str(lag_n), F.avg(col(col_name)).over(wSpec))\n",
    "        print(\"Lag = %d, Column = %s\" % (lag_n, col_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "err_mean.show(3)\n",
    "err_mean.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resample error time variable to every 3 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt_truncated = ((round(unix_timestamp(col(\"datetime\")) / time_val) * time_val)\n",
    "    .cast(\"timestamp\"))\n",
    "\n",
    "err_mean_resampled = (err_mean.withColumn(\"dt_truncated\", dt_truncated)\n",
    "                    .drop('error1sum', 'error2sum', 'error3sum', 'error4sum', 'error5sum').fillna(0))\n",
    "err_mean_resampled.show(5)\n",
    "err_mean_resampled.dtypes\n",
    "\n",
    "err_mean_resampled1 = (err_mean_resampled.groupBy(\"machineID\",\"dt_truncated\")\n",
    "                               .agg(F.mean('error1sum_rollingmean_24').alias('error1sum_rollingmean_24'), \n",
    "                                    F.mean('error2sum_rollingmean_24').alias('error2sum_rollingmean_24'), \n",
    "                                    F.mean('error3sum_rollingmean_24').alias('error3sum_rollingmean_24'), \n",
    "                                    F.mean('error4sum_rollingmean_24').alias('error4sum_rollingmean_24'), \n",
    "                                    F.mean('error5sum_rollingmean_24').alias('error5sum_rollingmean_24')))\n",
    "err_mean_resampled1.show(5)\n",
    "err_mean_resampled1.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Days since last replacement from maintenance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maint.show(5)\n",
    "maint.toPandas()['comp'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a column for each comp \n",
    "maint1 = maint.groupBy(\"machineID\",\"datetime\",\"comp\").pivot('comp').agg(F.count('machineID').alias('dummy'))\n",
    "\n",
    "maint1.show(5, False)\n",
    "maint1.count(), len(error1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove the column called comp and fill in missing values\n",
    "maint2 = maint1.drop('comp').fillna(0)\n",
    "maint2.show(5, False)\n",
    "maint2.count(), len(maint2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combine maintenance for a given machine in a given hour\n",
    "maint3 = (maint2.groupBy(\"machineID\",\"datetime\").agg(F.sum('comp1').alias('comp1sum'), \n",
    "                                                    F.sum('comp2').alias('comp2sum'), \n",
    "                                                    F.sum('comp3').alias('comp3sum'),\n",
    "                                                    F.sum('comp4').alias('comp4sum')))\n",
    "\n",
    "maint3.show(5, False)\n",
    "maint3.count(), len(maint3.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## test code for days since last replacement\n",
    "maint3.show(5, False)\n",
    "maint3.count(), len(maint3.columns)\n",
    "maint3.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Days since last replacement for component-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_maint_comp1 = (maint3.where((col(\"comp1sum\") == '1')).withColumnRenamed('datetime','datetime_maint')\n",
    "                           .drop('comp2sum', 'comp3sum', 'comp4sum'))\n",
    "print(test_maint_comp1.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_tel_comp1 = (telemetry.withColumnRenamed('datetime','datetime_tel')\n",
    "                  .drop(telemetry.volt).drop(telemetry.rotate).drop(telemetry.pressure).drop(telemetry.vibration))\n",
    "test_tel_comp1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_maint_tel_comp1 = test_tel_comp1.join(test_maint_comp1, ((test_tel_comp1['machineID']==\n",
    "                                                               test_maint_comp1['machineID']) \n",
    "                                            & (test_tel_comp1['datetime_tel'] > test_maint_comp1['datetime_maint']) \n",
    "                                            & (test_maint_comp1['comp1sum'] == '1'))).drop(test_maint_comp1.machineID)\n",
    "test_maint_tel_comp1.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comp1 = (test_maint_tel_comp1.withColumn(\"sincelastcomp1\", \n",
    "              datediff(test_maint_tel_comp1.datetime_tel, test_maint_tel_comp1.datetime_maint))\n",
    "              .drop(test_maint_tel_comp1.datetime_maint).drop(test_maint_tel_comp1.comp1sum))\n",
    "comp1.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comp1.describe(\"sincelastcomp1\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Days since last replacement for component-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_maint_comp2 = (maint3.where(col(\"comp2sum\") == '1').withColumnRenamed('datetime','datetime_maint')\n",
    "                         .drop('comp1sum', 'comp3sum', 'comp4sum'))\n",
    "print(test_maint_comp2.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_tel_comp2 = (telemetry.withColumnRenamed('datetime','datetime_tel')\n",
    "                          .drop(telemetry.volt).drop(telemetry.rotate).drop(telemetry.pressure)\n",
    "                          .drop(telemetry.vibration))\n",
    "print(test_tel_comp2.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_maint_tel_comp2 = (test_tel_comp2.join(test_maint_comp2, ((test_tel_comp2['machineID']==\n",
    "                                                                test_maint_comp2['machineID']) \n",
    "                                        & (test_tel_comp2['datetime_tel'] > test_maint_comp2['datetime_maint']) \n",
    "                                        & (test_maint_comp2['comp2sum'] == '1') \n",
    "                                           )).drop(test_maint_comp2.machineID))\n",
    "test_maint_tel_comp2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comp2 = (test_maint_tel_comp2.withColumn(\"sincelastcomp2\", \n",
    "              datediff(test_maint_tel_comp2.datetime_tel, test_maint_tel_comp2.datetime_maint))\n",
    "              .drop(test_maint_tel_comp2.datetime_maint).drop(test_maint_tel_comp2.comp2sum))\n",
    "comp2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comp2.describe(\"sincelastcomp2\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Days since last replacement for component-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_maint_comp3 = (maint3.where(col(\"comp3sum\") == '1').withColumnRenamed('datetime','datetime_maint')\n",
    "                          .drop('comp1sum', 'comp2sum', 'comp4sum'))\n",
    "print(test_maint_comp3.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_tel_comp3 = (telemetry.withColumnRenamed('datetime','datetime_tel')\n",
    "                    .drop(telemetry.volt).drop(telemetry.rotate).drop(telemetry.pressure).drop(telemetry.vibration))\n",
    "print(test_tel_comp3.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_maint_tel_comp3 = test_tel_comp3.join(test_maint_comp3, ((test_tel_comp3['machineID']==\n",
    "                                                               test_maint_comp3['machineID']) \n",
    "                                        & (test_tel_comp3['datetime_tel'] > test_maint_comp3['datetime_maint']) \n",
    "                                        & (test_maint_comp3['comp3sum'] == '1') \n",
    "                                           )).drop(test_maint_comp3.machineID)\n",
    "test_maint_tel_comp3.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comp3 = (test_maint_tel_comp3.withColumn(\"sincelastcomp3\", \n",
    "              datediff(test_maint_tel_comp3.datetime_tel, test_maint_tel_comp3.datetime_maint))\n",
    "              .drop(test_maint_tel_comp3.datetime_maint).drop(test_maint_tel_comp3.comp3sum))\n",
    "comp3.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comp3.describe(\"sincelastcomp3\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Days since last replacement for component-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_maint_comp4 = (maint3.where(col(\"comp4sum\") == '1').withColumnRenamed('datetime','datetime_maint')\n",
    "                         .drop('comp1sum', 'comp2sum', 'comp3sum'))\n",
    "print(test_maint_comp4.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_tel_comp4 = (telemetry.withColumnRenamed('datetime','datetime_tel')\n",
    "                  .drop(telemetry.volt).drop(telemetry.rotate).drop(telemetry.pressure).drop(telemetry.vibration))\n",
    "print(test_tel_comp4.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_maint_tel_comp4 = test_tel_comp4.join(test_maint_comp4, ((test_tel_comp4['machineID']==\n",
    "                                                               test_maint_comp4['machineID']) \n",
    "                                        & (test_tel_comp4['datetime_tel'] > test_maint_comp4['datetime_maint']) \n",
    "                                        & (test_maint_comp4['comp4sum'] == '1'))).drop(test_maint_comp4.machineID)\n",
    "test_maint_tel_comp4.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comp4 = (test_maint_tel_comp4.withColumn(\"sincelastcomp4\", \n",
    "              datediff(test_maint_tel_comp4.datetime_tel, test_maint_tel_comp4.datetime_maint))\n",
    "              .drop(test_maint_tel_comp4.datetime_maint).drop(test_maint_tel_comp4.comp4sum))\n",
    "comp4.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comp4.describe(\"sincelastcomp4\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Combine comp1, comp2, comp3, comp4 to generate the maintenance feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# left join comp3, comp4 \n",
    "comp3_4 = (comp3.join(comp4, ((comp3['machineID'] == comp4['machineID']) \n",
    "                                  & (comp3['datetime_tel'] == comp4['datetime_tel'])), \"left\")\n",
    "                                  .drop(comp4.machineID).drop(comp4.datetime_tel))\n",
    "comp3_4.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# left join comp2 with (comp3, comp4) \n",
    "comp2_3_4 = (comp2.join(comp3_4, ((comp2['machineID'] == comp3_4['machineID']) \n",
    "                                  & (comp2['datetime_tel'] == comp3_4['datetime_tel'])), \"left\")\n",
    "                                  .drop(comp3_4.machineID).drop(comp3_4.datetime_tel))\n",
    "comp2_3_4.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# left join comp1 with (comp2, comp3, comp4) \n",
    "comp1_2_3_4 = (comp1.join(comp2_3_4, ((comp1['machineID'] == comp2_3_4['machineID']) \n",
    "                                  & (comp1['datetime_tel'] == comp2_3_4['datetime_tel'])), \"left\")\n",
    "                                 .drop(comp2_3_4.machineID).drop(comp2_3_4.datetime_tel))\n",
    "comp1_2_3_4.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comp1_2_3_4_final = (comp1_2_3_4.groupBy(\"machineID\", \"datetime_tel\")\n",
    "                                .agg(F.max('sincelastcomp1').alias('sincelastcomp1'), \n",
    "                                     F.max('sincelastcomp2').alias('sincelastcomp2'), \n",
    "                                     F.max('sincelastcomp3').alias('sincelastcomp3'), \n",
    "                                     F.max('sincelastcomp4').alias('sincelastcomp4')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comp1_2_3_4_final.show(5)\n",
    "#comp1_2_3_4_final.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fill in missing value\n",
    "maint_count1 = comp1_2_3_4_final.fillna(0)\n",
    "\n",
    "maint_count1.show(5, False)\n",
    "#maint_count1.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resample maintenance time variable to every 3 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# maint_count1 maintenance \n",
    "dt_truncated = ((round(unix_timestamp(col(\"datetime_tel\")) / time_val) * time_val)\n",
    "    .cast(\"timestamp\"))\n",
    "\n",
    "maint_resampled = maint_count1.withColumn(\"dt_truncated\", dt_truncated)\n",
    "maint_resampled.show(5)\n",
    "maint_resampled.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maint_resampled1 = (maint_resampled.groupBy(\"machineID\",\"dt_truncated\")\n",
    "                                  .agg(F.mean('sincelastcomp1').alias('comp1sum'), \n",
    "                                       F.mean('sincelastcomp2').alias('comp2sum'), \n",
    "                                       F.mean('sincelastcomp3').alias('comp3sum'), \n",
    "                                       F.mean('sincelastcomp4').alias('comp4sum')))\n",
    "maint_resampled1.show(5)\n",
    "#maint_resampled1.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine features - need to do one hot encoding for variable model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check sample data\n",
    "machines.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one hot encoding of the variable model\n",
    "catVarNames = ['model']  \n",
    "    \n",
    "sIndexers = [StringIndexer(inputCol=x, outputCol=x + '_indexed') for x in catVarNames]\n",
    "\n",
    "machines_cat = Pipeline(stages=sIndexers).fit(machines).transform(machines)\n",
    "\n",
    "# one-hot encode\n",
    "ohEncoders = [OneHotEncoder(inputCol=x + '_indexed', outputCol=x + '_encoded')\n",
    "              for x in catVarNames]\n",
    "ohPipelineModel = Pipeline(stages=ohEncoders).fit(machines_cat)\n",
    "machines_cat = ohPipelineModel.transform(machines_cat)\n",
    "\n",
    "drop_list = [col_n for col_n in machines_cat.columns if 'indexed' in col_n]\n",
    "\n",
    "machines_edit = machines_cat.select([column for column in machines_cat.columns if column not in drop_list])\n",
    "\n",
    "machines_edit.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating final feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# join error with components\n",
    "#err_mean_resampled1.show(3)\n",
    "#maint_resampled1.show(3)\n",
    "\n",
    "error_maint = (err_mean_resampled1.join(maint_resampled1, \n",
    "                                ((err_mean_resampled1['machineID'] == maint_resampled1['machineID']) \n",
    "                                  & (err_mean_resampled1['dt_truncated'] == maint_resampled1['dt_truncated'])), \"left\")\n",
    "                                  .drop(maint_resampled1.machineID).drop(maint_resampled1.dt_truncated))\n",
    "#error_maint.show(10, False)\n",
    "#error_maint.count(), len(error_maint.columns)\n",
    "\n",
    "# now join with machines\n",
    "#machines_edit.show(1)\n",
    "\n",
    "err_maint_mach = (error_maint.join(machines_edit, ((error_maint['machineID'] == machines_edit['machineID'])), \"left\")\n",
    "                             .drop(machines_edit.machineID))\n",
    "err_maint_mach_select = (err_maint_mach.select([c for c in err_maint_mach.columns if c not in \n",
    "                                               {'error1sum', 'error2sum', 'error3sum', 'error4sum', 'error5sum'}]))\n",
    "#err_maint_mach_select.show(10, False)\n",
    "#err_maint_mach_select.count(), len(err_maint_mach_select.columns)\n",
    "\n",
    "telemetry_all = (tel_mean_resampled1.join(tel_sd_resampled1, \n",
    "                             ((tel_mean_resampled1['machineID'] == tel_sd_resampled1['machineID']) \n",
    "                              & (tel_mean_resampled1['dt_truncated'] == tel_sd_resampled1['dt_truncated'])), \"left\")\n",
    "                              .drop(tel_sd_resampled1.machineID).drop(tel_sd_resampled1.dt_truncated))\n",
    "#telemetry_all.show(10, False)\n",
    "#telemetry_all.count(), len(telemetry_all.columns)\n",
    "\n",
    "# join telemetry_all with err_maint_mach_select to create final feature matrix\n",
    "final_feat = (telemetry_all.join(err_maint_mach_select, \n",
    "                                ((telemetry_all['machineID'] == err_maint_mach_select['machineID']) \n",
    "                                  & (telemetry_all['dt_truncated'] == err_maint_mach_select['dt_truncated'])), \"left\")\n",
    "                                 .drop(err_maint_mach_select.machineID).drop(err_maint_mach_select.dt_truncated))\n",
    "final_feat.show(5, False)\n",
    "#final_feat.count(), len(final_feat.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Label construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check failure sample data\n",
    "failures.show(5)\n",
    "\n",
    "# check the dimensions of the data\n",
    "failures.count(), len(failures.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check to see if there are duplicate rows based on machine, datetime\n",
    "failures1 = failures.dropDuplicates(['machineID', 'datetime'])\n",
    "\n",
    "# check the dimensions of the data\n",
    "failures1.count(), len(failures1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# map the failure data to final feature matrix\n",
    "\n",
    "labeled_features = (final_feat.join(failures1, ((final_feat['machineID'] == failures1['machineID']) \n",
    "                                  & (final_feat['dt_truncated'] == failures1['datetime'])), \"left\")\n",
    "                                  .drop(failures1.machineID).drop(failures1.datetime))\n",
    "labeled_features.show(5, False)\n",
    "#labeled_features.count(), len(labeled_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# recoding the column 'failure' to be numeric double for the pyspark classification models\n",
    "labeled_features1 = (labeled_features.withColumn('failure', F.when(col('failure') == \"comp1\", 1.0)\n",
    "                                     .otherwise(col('failure')))\n",
    "                                     .withColumn('failure', F.when(col('failure') == \"comp2\", 2.0)\n",
    "                                     .otherwise(col('failure')))\n",
    "                                     .withColumn('failure', F.when(col('failure') == \"comp3\", 3.0)\n",
    "                                     .otherwise(col('failure')))\n",
    "                                     .withColumn('failure', F.when(col('failure') == \"comp4\", 4.0)\n",
    "                                     .otherwise(col('failure'))))\n",
    "\n",
    "labeled_features2 = labeled_features1.withColumn(\"failure1\", labeled_features1[\"failure\"].cast(DoubleType()))\n",
    "\n",
    "#labeled_features2.groupBy('failure').count().show()\n",
    "#labeled_features2.groupBy('failure1').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check data schema\n",
    "labeled_features2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeled_features3 = labeled_features2.drop('failure').fillna(0)\n",
    "labeled_features3.dtypes\n",
    "#labeled_features3.groupBy('failure1').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build the code for backfill with all machine data\n",
    "label_bfill1 = labeled_features3\n",
    "label_bfill1.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lag values to manually backfill label (bfill =7)\n",
    "my_window = Window.partitionBy('machineID').orderBy(label_bfill1.dt_truncated.desc())\n",
    "\n",
    "label_bfill1 = label_bfill1.withColumn(\"prev_value1\", F.lag(label_bfill1.failure1).over(my_window)).fillna(0)\n",
    "label_bfill1 = label_bfill1.withColumn(\"prev_value2\", F.lag(label_bfill1.prev_value1).over(my_window)).fillna(0) \n",
    "label_bfill1 = label_bfill1.withColumn(\"prev_value3\", F.lag(label_bfill1.prev_value2).over(my_window)).fillna(0) \n",
    "label_bfill1 = label_bfill1.withColumn(\"prev_value4\", F.lag(label_bfill1.prev_value3).over(my_window)).fillna(0) \n",
    "label_bfill1 = label_bfill1.withColumn(\"prev_value5\", F.lag(label_bfill1.prev_value4).over(my_window)).fillna(0) \n",
    "label_bfill1 = label_bfill1.withColumn(\"prev_value6\", F.lag(label_bfill1.prev_value5).over(my_window)).fillna(0) \n",
    "label_bfill1 = label_bfill1.withColumn(\"prev_value7\", F.lag(label_bfill1.prev_value6).over(my_window)).fillna(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create the label column \n",
    "label_bfill2 = (label_bfill1.withColumn('label', label_bfill1.failure1 + label_bfill1.prev_value1 \n",
    "                         + label_bfill1.prev_value2 + label_bfill1.prev_value3 + label_bfill1.prev_value4 \n",
    "                         + label_bfill1.prev_value5 + label_bfill1.prev_value6 + label_bfill1.prev_value7))\n",
    "label_bfill2 = label_bfill2.withColumn('label_e', F.when(col('label') > 4, 4.0).otherwise(col('label')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_bfill3 = (label_bfill2.drop(label_bfill2.prev_value1).drop(label_bfill2.prev_value2)\n",
    "              .drop(label_bfill2.prev_value3).drop(label_bfill2.prev_value4)\n",
    "              .drop(label_bfill2.prev_value5).drop(label_bfill2.prev_value6)\n",
    "              .drop(label_bfill2.prev_value7).drop(label_bfill2.label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_bfill3.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# you decide to partition the dataframe into three files and save them in the current folder.\n",
    "# if you wish to visualize them in the run history Output Files, specify the path \n",
    "# as './outputs/multiple_files.parquet'.\n",
    "#label_bfill3.coalesce(3).write.mode('overwrite').parquet('multiple_files.parquet')\n",
    "label_bfill3.write.mode('overwrite').parquet('featureengineering_files.parquet')\n",
    "\n",
    "# unlike the single file case, for multiple files we need to first delete results from the \n",
    "# previous run before uploading.\n",
    "for blob in my_service.list_blobs(CONTAINER_NAME):\n",
    "    if 'featureengineering_files.parquet' in blob.name:\n",
    "        my_service.delete_blob(CONTAINER_NAME, blob.name)\n",
    "\n",
    "# upload the entire folder into blob storage\n",
    "for name in glob.iglob('featureengineering_files.parquet/*'):\n",
    "    print(os.path.abspath(name))\n",
    "    my_service.create_blob_from_path(CONTAINER_NAME, name, name)\n",
    "\n",
    "print(\"Feature engineering final dataset files saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hack docker",
   "language": "python",
   "name": "hack_docker"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

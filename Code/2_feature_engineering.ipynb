{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Feature Engineering\n",
    "\n",
    "According to [Wikipedia, Feature engineering](https://en.wikipedia.org/wiki/Feature_engineering) is the process of using domain knowledge of the data to create features that make machine learning algorithms work. Feature engineering is fundamental to the application of machine learning, and is both difficult and expensive. \n",
    "\n",
    "This Feature engineering notebook loads and combines the data sources created in the together to create a single data set of features (variables) that can be used to infer a machines's health condition over time. \n",
    "\n",
    "This Feature engineering notebook will load the data sets created in the **Data Ingestion** notebook (`Code/1_data_ingestion.ipynb`) from an Azure storage container. The notebook will step through several feature engineering and labeling methods to create a single data set for use in our predictive maintenance machine learning solution.\n",
    "\n",
    "**Note:** This notebook will take about 20-30 minutes to execute all cells, depending on the compute configuration you have setup. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History logging enabled\n",
      "History logging is enabled\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<azureml.logging.script_run_request.ScriptRunRequest at 0x7fe082db92e8>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Setup our environment by importing required libraries\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Read csv file from URL directly\n",
    "import pandas as pd\n",
    "\n",
    "# For creating some preliminary EDA plots.\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from ggplot import *\n",
    "\n",
    "import datetime\n",
    "from pyspark.sql.functions import to_date\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import col, unix_timestamp, round\n",
    "from pyspark.sql.functions import datediff\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# For Azure blob storage access\n",
    "from azure.storage.blob import BlockBlobService\n",
    "from azure.storage.blob import PublicAccess\n",
    "\n",
    "# For logging model evaluation parameters back into the\n",
    "# AML Workbench run history plots.\n",
    "import logging\n",
    "from azureml.logging import get_azureml_logger\n",
    "\n",
    "amllog = logging.getLogger(\"azureml\")\n",
    "amllog.level = logging.INFO\n",
    "\n",
    "# Turn on cell level logging.\n",
    "%azureml history on\n",
    "%azureml history show\n",
    "\n",
    "# Time the notebook execution. \n",
    "# This will only make sense if you \"Run all cells\"\n",
    "tic = time.time()\n",
    "\n",
    "logger = get_azureml_logger() # logger writes to AMLWorkbench runtime view\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Telemetry\n",
    "logger.log('amlrealworld.predictivemaintenance.feature_engineering','true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from Azure Blob storage container\n",
    "\n",
    "In the **Data Ingestion** notebook (`Code/1_data_ingestion.ipynb`), we downloaded and stored the following data sets into Azure blob storage:\n",
    "\n",
    "  * **Machines**: Features differentiating each machine. For example age and model.\n",
    "  * **Error**: The log of non-critical errors. These errors may still indicate an impending component failure.\n",
    "  * **Maint**: Machine maintenance history detailing component replacement or regular maintenance activities withe the date of replacement.\n",
    "  * **Telemetry**: The operating conditions of a machine e.g. data collected from sensors.\n",
    "  * **Failure**: The failure history of a machine or component within the machine.\n",
    "\n",
    "We first load these files. Since the Azure Blob storage account name and account key are not passed between notebooks, you'll need to provide those here again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your Azure blob storage details here \n",
    "ACCOUNT_NAME = \"<your blob storage account name>\"\n",
    "\n",
    "# You can find the account key under the _Access Keys_ link in the \n",
    "# [Azure Portal](portal.azure.com) page for your Azure storage container.\n",
    "ACCOUNT_KEY = \"<your blob storage account key>\"\n",
    "\n",
    "# Enter your Azure blob storage details here \n",
    "ACCOUNT_NAME = \"pdmvienna\"\n",
    "\n",
    "# You can find the account key under the _Access Keys_ link in the \n",
    "# [Azure Portal](portal.azure.com) page for your Azure storage container.\n",
    "ACCOUNT_KEY = \"PDuXK61GpmMVWMrWdvr29THbPdlOXa61fN5RfgQV/jBO8berC1zLzZ678Nxrx+D3CRp4+ZvSff9al+lrUh8qUQ==\"\n",
    "#-------------------------------------------------------------------------------------------\n",
    "# The data from the Data Aquisition note book is stored in the dataingestion container.\n",
    "CONTAINER_NAME = \"dataingestion\"\n",
    "\n",
    "# The data constructed in this notebook will be stored in the featureengineering container\n",
    "STORAGE_CONTAINER_NAME = \"featureengineering\"\n",
    "\n",
    "# Connect to your blob service     \n",
    "az_blob_service = BlockBlobService(account_name=ACCOUNT_NAME, account_key=ACCOUNT_KEY)\n",
    "\n",
    "# We will store each of these data sets in blob storage in an \n",
    "# Azure Storage Container on your Azure subscription.\n",
    "# See https://github.com/Azure/ViennaDocs/blob/master/Documentation/UsingBlobForStorage.md\n",
    "# for details.\n",
    "\n",
    "# These file names detail which blob each file is stored under. \n",
    "MACH_DATA = 'machines_files.parquet'\n",
    "MAINT_DATA = 'maint_files.parquet'\n",
    "ERROR_DATA = 'errors_files.parquet'\n",
    "TELEMETRY_DATA = 'telemetry_files.parquet'\n",
    "FAILURE_DATA = 'failure_files.parquet'\n",
    "\n",
    "# These file names detail the local paths where we store the data results.\n",
    "MACH_LOCAL_DIRECT = 'dataingestion_mach_result.parquet'\n",
    "ERROR_LOCAL_DIRECT = 'dataingestion_err_result.parquet'\n",
    "MAINT_LOCAL_DIRECT = 'dataingestion_maint_result.parquet'\n",
    "TELEMETRY_LOCAL_DIRECT = 'dataingestion_tel_result.parquet'\n",
    "FAILURES_LOCAL_DIRECT = 'dataingestion_fail_result.parquet'\n",
    "\n",
    "# This is the final data file.\n",
    "FEATURES_LOCAL_DIRECT = 'featureengineering_files.parquet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machines data set\n",
    "\n",
    "Load the machines data set from your Azure blob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE creating a local directory!\n",
      "1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>machineID</th>\n",
       "      <th>model</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>model2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>model4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>model3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>model3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>model2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   machineID   model  age\n",
       "0          1  model2   18\n",
       "1          2  model4    7\n",
       "2          3  model3    8\n",
       "3          4  model3    7\n",
       "4          5  model2    2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a local path  to store the data.\n",
    "if not os.path.exists(MACH_LOCAL_DIRECT):\n",
    "    os.makedirs(MACH_LOCAL_DIRECT)\n",
    "    print('DONE creating a local directory!')\n",
    "\n",
    "# Connect to blob storage container\n",
    "for blob in az_blob_service.list_blobs(CONTAINER_NAME):\n",
    "    if MACH_DATA in blob.name:\n",
    "        local_file = os.path.join(MACH_LOCAL_DIRECT, os.path.basename(blob.name))\n",
    "        az_blob_service.get_blob_to_path(CONTAINER_NAME, blob.name, local_file)\n",
    "\n",
    "# Read in the data\n",
    "machines = spark.read.parquet(MACH_LOCAL_DIRECT)\n",
    "\n",
    "print(machines.count())\n",
    "machines.limit(5).toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Errors data set\n",
    "\n",
    "Load the errors data set from your Azure blob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE creating a local directory!\n",
      "11967\n",
      "root\n",
      " |-- datetime: string (nullable = true)\n",
      " |-- machineID: long (nullable = true)\n",
      " |-- errorID: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>machineID</th>\n",
       "      <th>errorID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-04-06 06:00:00</td>\n",
       "      <td>79</td>\n",
       "      <td>error5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-05-06 06:00:00</td>\n",
       "      <td>79</td>\n",
       "      <td>error1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-05-27 03:00:00</td>\n",
       "      <td>79</td>\n",
       "      <td>error2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-08-19 06:00:00</td>\n",
       "      <td>79</td>\n",
       "      <td>error2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-08-19 06:00:00</td>\n",
       "      <td>79</td>\n",
       "      <td>error3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime  machineID errorID\n",
       "0  2015-04-06 06:00:00         79  error5\n",
       "1  2015-05-06 06:00:00         79  error1\n",
       "2  2015-05-27 03:00:00         79  error2\n",
       "3  2015-08-19 06:00:00         79  error2\n",
       "4  2015-08-19 06:00:00         79  error3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not os.path.exists(ERROR_LOCAL_DIRECT):\n",
    "    os.makedirs(ERROR_LOCAL_DIRECT)\n",
    "    print('DONE creating a local directory!')\n",
    "\n",
    "# Connect to blob storage container\n",
    "for blob in az_blob_service.list_blobs(CONTAINER_NAME):\n",
    "    if ERROR_DATA in blob.name:\n",
    "        local_file = os.path.join(ERROR_LOCAL_DIRECT, os.path.basename(blob.name))\n",
    "        az_blob_service.get_blob_to_path(CONTAINER_NAME, blob.name, local_file)\n",
    "\n",
    "# Read in the data\n",
    "errors = spark.read.parquet(ERROR_LOCAL_DIRECT)\n",
    "\n",
    "print(errors.count())\n",
    "errors.printSchema()\n",
    "errors.limit(5).toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maintenance data set\n",
    "\n",
    "Load the maintenance data set from your Azure blob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE creating a local directory!\n",
      "32592\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>machineID</th>\n",
       "      <th>comp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-05-31 06:00:00</td>\n",
       "      <td>125</td>\n",
       "      <td>comp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-05-31 06:00:00</td>\n",
       "      <td>125</td>\n",
       "      <td>comp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-06-15 06:00:00</td>\n",
       "      <td>125</td>\n",
       "      <td>comp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-06-15 06:00:00</td>\n",
       "      <td>125</td>\n",
       "      <td>comp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-07-15 06:00:00</td>\n",
       "      <td>125</td>\n",
       "      <td>comp2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime  machineID   comp\n",
       "0  2015-05-31 06:00:00        125  comp3\n",
       "1  2015-05-31 06:00:00        125  comp4\n",
       "2  2015-06-15 06:00:00        125  comp4\n",
       "3  2015-06-15 06:00:00        125  comp3\n",
       "4  2015-07-15 06:00:00        125  comp2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a local path  to store the data.\n",
    "if not os.path.exists(MAINT_LOCAL_DIRECT):\n",
    "    os.makedirs(MAINT_LOCAL_DIRECT)\n",
    "    print('DONE creating a local directory!')\n",
    "\n",
    "# Connect to blob storage container\n",
    "for blob in az_blob_service.list_blobs(CONTAINER_NAME):\n",
    "    if MAINT_DATA in blob.name:\n",
    "        local_file = os.path.join(MAINT_LOCAL_DIRECT, os.path.basename(blob.name))\n",
    "        az_blob_service.get_blob_to_path(CONTAINER_NAME, blob.name, local_file)\n",
    "\n",
    "# Read in the data\n",
    "maint = spark.read.parquet(MAINT_LOCAL_DIRECT)\n",
    "\n",
    "print(maint.count())\n",
    "maint.limit(5).toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Telemetry\n",
    "\n",
    "Load the telemetry data set from your Azure blob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE creating a local directory!\n",
      "8761000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>machineID</th>\n",
       "      <th>volt</th>\n",
       "      <th>rotate</th>\n",
       "      <th>pressure</th>\n",
       "      <th>vibration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-12-19 22:00:00</td>\n",
       "      <td>625</td>\n",
       "      <td>138.923911</td>\n",
       "      <td>332.555602</td>\n",
       "      <td>99.460533</td>\n",
       "      <td>43.493783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-12-19 23:00:00</td>\n",
       "      <td>625</td>\n",
       "      <td>173.839769</td>\n",
       "      <td>335.473306</td>\n",
       "      <td>103.150583</td>\n",
       "      <td>46.760175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-12-20 00:00:00</td>\n",
       "      <td>625</td>\n",
       "      <td>177.709243</td>\n",
       "      <td>456.502368</td>\n",
       "      <td>94.547367</td>\n",
       "      <td>42.063502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-12-20 01:00:00</td>\n",
       "      <td>625</td>\n",
       "      <td>176.464697</td>\n",
       "      <td>438.722509</td>\n",
       "      <td>106.360646</td>\n",
       "      <td>36.449788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-12-20 02:00:00</td>\n",
       "      <td>625</td>\n",
       "      <td>177.080815</td>\n",
       "      <td>407.972662</td>\n",
       "      <td>92.472901</td>\n",
       "      <td>33.644790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime  machineID        volt      rotate    pressure  \\\n",
       "0  2015-12-19 22:00:00        625  138.923911  332.555602   99.460533   \n",
       "1  2015-12-19 23:00:00        625  173.839769  335.473306  103.150583   \n",
       "2  2015-12-20 00:00:00        625  177.709243  456.502368   94.547367   \n",
       "3  2015-12-20 01:00:00        625  176.464697  438.722509  106.360646   \n",
       "4  2015-12-20 02:00:00        625  177.080815  407.972662   92.472901   \n",
       "\n",
       "   vibration  \n",
       "0  43.493783  \n",
       "1  46.760175  \n",
       "2  42.063502  \n",
       "3  36.449788  \n",
       "4  33.644790  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a local path  to store the data.\n",
    "if not os.path.exists(TELEMETRY_LOCAL_DIRECT):\n",
    "    os.makedirs(TELEMETRY_LOCAL_DIRECT)\n",
    "    print('DONE creating a local directory!')\n",
    "\n",
    "# Connect to blob storage container\n",
    "for blob in az_blob_service.list_blobs(CONTAINER_NAME):\n",
    "    if TELEMETRY_DATA in blob.name:\n",
    "        local_file = os.path.join(TELEMETRY_LOCAL_DIRECT, os.path.basename(blob.name))\n",
    "        az_blob_service.get_blob_to_path(CONTAINER_NAME, blob.name, local_file)\n",
    "\n",
    "# Read in the data\n",
    "telemetry = spark.read.parquet(TELEMETRY_LOCAL_DIRECT)\n",
    "\n",
    "print(telemetry.count())\n",
    "telemetry.limit(5).toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Failures data set\n",
    "\n",
    "Load the failures data set from your Azure blob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE creating a local directory!\n",
      "6368\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>machineID</th>\n",
       "      <th>failure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-07-31 06:00:00</td>\n",
       "      <td>7</td>\n",
       "      <td>comp1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-02-17 06:00:00</td>\n",
       "      <td>179</td>\n",
       "      <td>comp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-12-28 06:00:00</td>\n",
       "      <td>191</td>\n",
       "      <td>comp1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-06-13 06:00:00</td>\n",
       "      <td>221</td>\n",
       "      <td>comp2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-06-28 06:00:00</td>\n",
       "      <td>262</td>\n",
       "      <td>comp2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime  machineID failure\n",
       "0  2015-07-31 06:00:00          7   comp1\n",
       "1  2015-02-17 06:00:00        179   comp4\n",
       "2  2015-12-28 06:00:00        191   comp1\n",
       "3  2015-06-13 06:00:00        221   comp2\n",
       "4  2015-06-28 06:00:00        262   comp2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a local path  to store the data.\n",
    "if not os.path.exists(FAILURES_LOCAL_DIRECT):\n",
    "    os.makedirs(FAILURES_LOCAL_DIRECT)\n",
    "    print('DONE creating a local directory!')\n",
    "\n",
    "\n",
    "# download the entire parquet result folder to local path for a new run \n",
    "for blob in az_blob_service.list_blobs(CONTAINER_NAME):\n",
    "    if FAILURE_DATA in blob.name:\n",
    "        local_file = os.path.join(FAILURES_LOCAL_DIRECT, os.path.basename(blob.name))\n",
    "        az_blob_service.get_blob_to_path(CONTAINER_NAME, blob.name, local_file)\n",
    "\n",
    "failures = spark.read.parquet(FAILURES_LOCAL_DIRECT).dropDuplicates(['machineID', 'datetime'])\n",
    "\n",
    "print(failures.count())\n",
    "failures.limit(5).toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering \n",
    "\n",
    "Our feature engineering will first combine the different data sources together to create a single data set of features (variables) that can be used to infer a machines's health condition over time. The ultimate goal is to generate a single record for each time unit for each asset which combines features and labels to be fed into the machine learning algorithm. In order to prepare final data set, some pre-processing steps will be taken. The first step is to divide the duration of data collection into time units where each record belongs to a single point in time for each asset.\n",
    "\n",
    "The measurement unit for time can be in seconds, minutes, hours, days, months, cycles, miles or transactions. The measurement choice is typically specific to the use case domain. Additionally, the time unit does not have to be the same as the frequency of data collection. For example, if temperature values were being collected every 10 seconds, picking a time unit of 10 seconds for the whole analysis inflates the number of examples without providing any additional information if the temperature only changes slowly. A better strategy is to average the temperature over a longer time horizon which might better capture variations that could theoretically contribute to the outcome we would like to predict.\n",
    "\n",
    "Predictive maintenance analysis can be characterised as a classification method involving time series data. Time series, since we want to use historical observations to predict what will happen in the future. Classification, because we classify the future as having a probability of failure. \n",
    "\n",
    "### Lag features\n",
    "\n",
    "As mentioned earlier, in predictive maintenance, historical data usually comes with timestamps indicating the time of collection for each piece of data. There are many ways of creating features from the data that comes with timestamped data. In this section, we discuss some of these methods used for predictive maintenance. However, we are not limited by these methods alone. Since feature engineering is considered to be one of the most creative areas of predictive modeling, there could be many other ways to create features. Here, we provide some general techniques.\n",
    "\n",
    "### Rolling aggregates\n",
    "\n",
    "For each record of an asset we pick a rolling window of size `W`, then compute rolling aggregate features using observations within the window `W` the date of each record. Some example rolling aggregates can be rolling counts, means, standard deviations, outliers based on standard deviations, CUSUM measures, minimum and maximum values for the window. Another interesting technique is to capture trend changes, spikes and level changes using algorithms that detect anomalies in data using anomaly detection algorithms.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Telemetry features\n",
    "\n",
    "Because the telemetry data set is the largest time series data we have, we start feature engineering here. \n",
    "\n",
    "A common method is to pick a window size for the lag features to be created and compute rolling aggregate measures such as mean, standard deviation, minimum, maximum, etc. to represent the short term history of the telemetry over the window. In the following, rolling mean and standard deviation of the telemetry data over the last 3 hour and 24 hour lag windows is calculated for every 3 hours.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rolling mean and standard deviation\n",
    "# Temporary storage for rolling means\n",
    "tel_mean = telemetry\n",
    "\n",
    "# Which features are we interested in telemetry data set\n",
    "rolling_features = ['volt','rotate', 'pressure', 'vibration']\n",
    "      \n",
    "# n hours = n * 3600 seconds  \n",
    "time_val = 12 * 3600\n",
    "\n",
    "# Choose the 3 hour timestamps to align the data\n",
    "# dt_truncated looks at the column named \"datetime\" in the current data set.\n",
    "# remember that Spark is lazy... this doesn't execute until it is in a withColumn statement.\n",
    "dt_truncated = ((round(unix_timestamp(col(\"datetime\")) / time_val) * time_val).cast(\"timestamp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "731000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>machineID</th>\n",
       "      <th>dt_truncated</th>\n",
       "      <th>volt_rollingmean_12</th>\n",
       "      <th>rotate_rollingmean_12</th>\n",
       "      <th>pressure_rollingmean_12</th>\n",
       "      <th>vibration_rollingmean_12</th>\n",
       "      <th>volt_rollingmean_24</th>\n",
       "      <th>rotate_rollingmean_24</th>\n",
       "      <th>pressure_rollingmean_24</th>\n",
       "      <th>vibration_rollingmean_24</th>\n",
       "      <th>...</th>\n",
       "      <th>pressure_rollingstd_12</th>\n",
       "      <th>vibration_rollingstd_12</th>\n",
       "      <th>volt_rollingstd_24</th>\n",
       "      <th>rotate_rollingstd_24</th>\n",
       "      <th>pressure_rollingstd_24</th>\n",
       "      <th>vibration_rollingstd_24</th>\n",
       "      <th>volt_rollingstd_36</th>\n",
       "      <th>rotate_rollingstd_36</th>\n",
       "      <th>pressure_rollingstd_36</th>\n",
       "      <th>vibration_rollingstd_36</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-04-02 12:00:00</td>\n",
       "      <td>172.270947</td>\n",
       "      <td>453.797903</td>\n",
       "      <td>100.483543</td>\n",
       "      <td>39.492142</td>\n",
       "      <td>171.338531</td>\n",
       "      <td>447.862397</td>\n",
       "      <td>100.398683</td>\n",
       "      <td>39.738176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.553654</td>\n",
       "      <td>0.759006</td>\n",
       "      <td>1.007532</td>\n",
       "      <td>3.219369</td>\n",
       "      <td>0.223788</td>\n",
       "      <td>0.157623</td>\n",
       "      <td>0.629986</td>\n",
       "      <td>0.722444</td>\n",
       "      <td>0.481365</td>\n",
       "      <td>0.088545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-12 00:00:00</td>\n",
       "      <td>171.869404</td>\n",
       "      <td>453.529162</td>\n",
       "      <td>100.214013</td>\n",
       "      <td>40.171795</td>\n",
       "      <td>171.649903</td>\n",
       "      <td>458.103907</td>\n",
       "      <td>101.813178</td>\n",
       "      <td>40.830119</td>\n",
       "      <td>...</td>\n",
       "      <td>1.950677</td>\n",
       "      <td>0.954435</td>\n",
       "      <td>0.732750</td>\n",
       "      <td>2.007912</td>\n",
       "      <td>1.015522</td>\n",
       "      <td>0.472419</td>\n",
       "      <td>0.561696</td>\n",
       "      <td>0.988960</td>\n",
       "      <td>0.580570</td>\n",
       "      <td>0.306208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-07-26 12:00:00</td>\n",
       "      <td>167.325797</td>\n",
       "      <td>450.548728</td>\n",
       "      <td>96.380156</td>\n",
       "      <td>41.093641</td>\n",
       "      <td>168.417015</td>\n",
       "      <td>446.610707</td>\n",
       "      <td>97.754618</td>\n",
       "      <td>39.830570</td>\n",
       "      <td>...</td>\n",
       "      <td>0.948548</td>\n",
       "      <td>0.460620</td>\n",
       "      <td>0.834651</td>\n",
       "      <td>1.777865</td>\n",
       "      <td>0.496723</td>\n",
       "      <td>0.181640</td>\n",
       "      <td>0.458351</td>\n",
       "      <td>1.382999</td>\n",
       "      <td>0.176032</td>\n",
       "      <td>0.107555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-08-04 00:00:00</td>\n",
       "      <td>170.231819</td>\n",
       "      <td>482.393571</td>\n",
       "      <td>98.709572</td>\n",
       "      <td>39.771546</td>\n",
       "      <td>171.876957</td>\n",
       "      <td>473.301415</td>\n",
       "      <td>103.358692</td>\n",
       "      <td>43.025796</td>\n",
       "      <td>...</td>\n",
       "      <td>1.007066</td>\n",
       "      <td>0.634358</td>\n",
       "      <td>0.546013</td>\n",
       "      <td>1.609741</td>\n",
       "      <td>1.535208</td>\n",
       "      <td>0.333413</td>\n",
       "      <td>0.546630</td>\n",
       "      <td>1.585655</td>\n",
       "      <td>0.186535</td>\n",
       "      <td>0.133264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-08-23 12:00:00</td>\n",
       "      <td>170.203712</td>\n",
       "      <td>425.094036</td>\n",
       "      <td>101.529310</td>\n",
       "      <td>39.173365</td>\n",
       "      <td>167.913767</td>\n",
       "      <td>447.531697</td>\n",
       "      <td>100.026931</td>\n",
       "      <td>38.672964</td>\n",
       "      <td>...</td>\n",
       "      <td>1.640248</td>\n",
       "      <td>0.397124</td>\n",
       "      <td>0.951870</td>\n",
       "      <td>4.648390</td>\n",
       "      <td>1.638073</td>\n",
       "      <td>0.297089</td>\n",
       "      <td>0.823227</td>\n",
       "      <td>2.742029</td>\n",
       "      <td>0.467837</td>\n",
       "      <td>0.189906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-12-17 00:00:00</td>\n",
       "      <td>169.167041</td>\n",
       "      <td>455.734514</td>\n",
       "      <td>98.842483</td>\n",
       "      <td>39.104152</td>\n",
       "      <td>171.370731</td>\n",
       "      <td>452.306194</td>\n",
       "      <td>98.278780</td>\n",
       "      <td>42.471398</td>\n",
       "      <td>...</td>\n",
       "      <td>1.031176</td>\n",
       "      <td>0.801300</td>\n",
       "      <td>0.874356</td>\n",
       "      <td>2.523363</td>\n",
       "      <td>1.116471</td>\n",
       "      <td>0.800095</td>\n",
       "      <td>0.505470</td>\n",
       "      <td>2.272075</td>\n",
       "      <td>0.260917</td>\n",
       "      <td>0.302917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-02-16 12:00:00</td>\n",
       "      <td>167.881679</td>\n",
       "      <td>459.764609</td>\n",
       "      <td>95.996968</td>\n",
       "      <td>41.355194</td>\n",
       "      <td>173.957011</td>\n",
       "      <td>452.269318</td>\n",
       "      <td>99.137917</td>\n",
       "      <td>40.716012</td>\n",
       "      <td>...</td>\n",
       "      <td>1.038664</td>\n",
       "      <td>0.734094</td>\n",
       "      <td>1.594118</td>\n",
       "      <td>4.929011</td>\n",
       "      <td>0.532804</td>\n",
       "      <td>0.139801</td>\n",
       "      <td>1.130919</td>\n",
       "      <td>3.430454</td>\n",
       "      <td>0.376233</td>\n",
       "      <td>0.134925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-10-30 12:00:00</td>\n",
       "      <td>171.302151</td>\n",
       "      <td>458.251722</td>\n",
       "      <td>100.603054</td>\n",
       "      <td>47.070461</td>\n",
       "      <td>169.921885</td>\n",
       "      <td>457.776886</td>\n",
       "      <td>98.524571</td>\n",
       "      <td>44.258167</td>\n",
       "      <td>...</td>\n",
       "      <td>1.684044</td>\n",
       "      <td>1.263139</td>\n",
       "      <td>0.323506</td>\n",
       "      <td>3.108947</td>\n",
       "      <td>0.426392</td>\n",
       "      <td>0.751400</td>\n",
       "      <td>0.352569</td>\n",
       "      <td>1.753114</td>\n",
       "      <td>0.381185</td>\n",
       "      <td>0.762853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-10-31 12:00:00</td>\n",
       "      <td>172.983326</td>\n",
       "      <td>409.865155</td>\n",
       "      <td>96.193019</td>\n",
       "      <td>51.727068</td>\n",
       "      <td>170.658641</td>\n",
       "      <td>424.695800</td>\n",
       "      <td>96.454905</td>\n",
       "      <td>51.746030</td>\n",
       "      <td>...</td>\n",
       "      <td>1.236143</td>\n",
       "      <td>0.363418</td>\n",
       "      <td>0.370740</td>\n",
       "      <td>11.858567</td>\n",
       "      <td>0.182346</td>\n",
       "      <td>0.205475</td>\n",
       "      <td>0.300758</td>\n",
       "      <td>6.649440</td>\n",
       "      <td>0.380280</td>\n",
       "      <td>0.680251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-12-11 12:00:00</td>\n",
       "      <td>173.352547</td>\n",
       "      <td>448.775731</td>\n",
       "      <td>101.412437</td>\n",
       "      <td>39.027765</td>\n",
       "      <td>171.292002</td>\n",
       "      <td>444.774327</td>\n",
       "      <td>101.879997</td>\n",
       "      <td>39.588702</td>\n",
       "      <td>...</td>\n",
       "      <td>1.520909</td>\n",
       "      <td>0.524005</td>\n",
       "      <td>0.491613</td>\n",
       "      <td>2.037811</td>\n",
       "      <td>0.483161</td>\n",
       "      <td>0.292491</td>\n",
       "      <td>0.961163</td>\n",
       "      <td>2.095341</td>\n",
       "      <td>0.306276</td>\n",
       "      <td>0.286464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   machineID        dt_truncated  volt_rollingmean_12  rotate_rollingmean_12  \\\n",
       "0          1 2015-04-02 12:00:00           172.270947             453.797903   \n",
       "1          1 2015-05-12 00:00:00           171.869404             453.529162   \n",
       "2          1 2015-07-26 12:00:00           167.325797             450.548728   \n",
       "3          1 2015-08-04 00:00:00           170.231819             482.393571   \n",
       "4          1 2015-08-23 12:00:00           170.203712             425.094036   \n",
       "5          1 2015-12-17 00:00:00           169.167041             455.734514   \n",
       "6          1 2015-02-16 12:00:00           167.881679             459.764609   \n",
       "7          1 2015-10-30 12:00:00           171.302151             458.251722   \n",
       "8          1 2015-10-31 12:00:00           172.983326             409.865155   \n",
       "9          1 2015-12-11 12:00:00           173.352547             448.775731   \n",
       "\n",
       "   pressure_rollingmean_12  vibration_rollingmean_12  volt_rollingmean_24  \\\n",
       "0               100.483543                 39.492142           171.338531   \n",
       "1               100.214013                 40.171795           171.649903   \n",
       "2                96.380156                 41.093641           168.417015   \n",
       "3                98.709572                 39.771546           171.876957   \n",
       "4               101.529310                 39.173365           167.913767   \n",
       "5                98.842483                 39.104152           171.370731   \n",
       "6                95.996968                 41.355194           173.957011   \n",
       "7               100.603054                 47.070461           169.921885   \n",
       "8                96.193019                 51.727068           170.658641   \n",
       "9               101.412437                 39.027765           171.292002   \n",
       "\n",
       "   rotate_rollingmean_24  pressure_rollingmean_24  vibration_rollingmean_24  \\\n",
       "0             447.862397               100.398683                 39.738176   \n",
       "1             458.103907               101.813178                 40.830119   \n",
       "2             446.610707                97.754618                 39.830570   \n",
       "3             473.301415               103.358692                 43.025796   \n",
       "4             447.531697               100.026931                 38.672964   \n",
       "5             452.306194                98.278780                 42.471398   \n",
       "6             452.269318                99.137917                 40.716012   \n",
       "7             457.776886                98.524571                 44.258167   \n",
       "8             424.695800                96.454905                 51.746030   \n",
       "9             444.774327               101.879997                 39.588702   \n",
       "\n",
       "            ...             pressure_rollingstd_12  vibration_rollingstd_12  \\\n",
       "0           ...                           0.553654                 0.759006   \n",
       "1           ...                           1.950677                 0.954435   \n",
       "2           ...                           0.948548                 0.460620   \n",
       "3           ...                           1.007066                 0.634358   \n",
       "4           ...                           1.640248                 0.397124   \n",
       "5           ...                           1.031176                 0.801300   \n",
       "6           ...                           1.038664                 0.734094   \n",
       "7           ...                           1.684044                 1.263139   \n",
       "8           ...                           1.236143                 0.363418   \n",
       "9           ...                           1.520909                 0.524005   \n",
       "\n",
       "   volt_rollingstd_24  rotate_rollingstd_24  pressure_rollingstd_24  \\\n",
       "0            1.007532              3.219369                0.223788   \n",
       "1            0.732750              2.007912                1.015522   \n",
       "2            0.834651              1.777865                0.496723   \n",
       "3            0.546013              1.609741                1.535208   \n",
       "4            0.951870              4.648390                1.638073   \n",
       "5            0.874356              2.523363                1.116471   \n",
       "6            1.594118              4.929011                0.532804   \n",
       "7            0.323506              3.108947                0.426392   \n",
       "8            0.370740             11.858567                0.182346   \n",
       "9            0.491613              2.037811                0.483161   \n",
       "\n",
       "   vibration_rollingstd_24  volt_rollingstd_36  rotate_rollingstd_36  \\\n",
       "0                 0.157623            0.629986              0.722444   \n",
       "1                 0.472419            0.561696              0.988960   \n",
       "2                 0.181640            0.458351              1.382999   \n",
       "3                 0.333413            0.546630              1.585655   \n",
       "4                 0.297089            0.823227              2.742029   \n",
       "5                 0.800095            0.505470              2.272075   \n",
       "6                 0.139801            1.130919              3.430454   \n",
       "7                 0.751400            0.352569              1.753114   \n",
       "8                 0.205475            0.300758              6.649440   \n",
       "9                 0.292491            0.961163              2.095341   \n",
       "\n",
       "   pressure_rollingstd_36  vibration_rollingstd_36  \n",
       "0                0.481365                 0.088545  \n",
       "1                0.580570                 0.306208  \n",
       "2                0.176032                 0.107555  \n",
       "3                0.186535                 0.133264  \n",
       "4                0.467837                 0.189906  \n",
       "5                0.260917                 0.302917  \n",
       "6                0.376233                 0.134925  \n",
       "7                0.381185                 0.762853  \n",
       "8                0.380280                 0.680251  \n",
       "9                0.306276                 0.286464  \n",
       "\n",
       "[10 rows x 26 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We choose two windows for our rolling windows 3hrs, 24 hrs\n",
    "lags = [12,24,36]\n",
    "\n",
    "# Lag the \n",
    "for lag_n in lags:\n",
    "    wSpec = Window.partitionBy('machineID').orderBy('datetime').rowsBetween(1-lag_n, 0)\n",
    "    for col_name in rolling_features:\n",
    "        tel_mean = tel_mean.withColumn(col_name+'_rollingmean_'+str(lag_n), F.avg(col(col_name)).over(wSpec))\n",
    "        tel_mean = tel_mean.withColumn(col_name+'_rollingstd_'+str(lag_n), F.stddev(col(col_name)).over(wSpec))\n",
    "\n",
    "# Write a custom function to convert the data type of DataFrame columns\n",
    "def convertColumn(df, names, newType):\n",
    "  for name in names: \n",
    "     df = df.withColumn(name, df[name].cast(newType))\n",
    "  return df \n",
    "\n",
    "telemetry_feat = (tel_mean.withColumn(\"dt_truncated\", dt_truncated)\n",
    "                  .drop('volt', 'rotate', 'pressure', 'vibration')\n",
    "                  .fillna(0)\n",
    "                  .groupBy(\"machineID\",\"dt_truncated\")\n",
    "                  .agg(F.mean('volt_rollingmean_12').alias('volt_rollingmean_12'),\n",
    "                       F.mean('rotate_rollingmean_12').alias('rotate_rollingmean_12'), \n",
    "                       F.mean('pressure_rollingmean_12').alias('pressure_rollingmean_12'), \n",
    "                       F.mean('vibration_rollingmean_12').alias('vibration_rollingmean_12'), \n",
    "                       F.mean('volt_rollingmean_24').alias('volt_rollingmean_24'),\n",
    "                       F.mean('rotate_rollingmean_24').alias('rotate_rollingmean_24'), \n",
    "                       F.mean('pressure_rollingmean_24').alias('pressure_rollingmean_24'), \n",
    "                       F.mean('vibration_rollingmean_24').alias('vibration_rollingmean_24'),\n",
    "                       F.mean('volt_rollingmean_36').alias('volt_rollingmean_36'),\n",
    "                       F.mean('vibration_rollingmean_36').alias('vibration_rollingmean_36'),\n",
    "                       F.mean('rotate_rollingmean_36').alias('rotate_rollingmean_36'), \n",
    "                       F.mean('pressure_rollingmean_36').alias('pressure_rollingmean_36'), \n",
    "                       F.stddev('volt_rollingstd_12').alias('volt_rollingstd_12'),\n",
    "                       F.stddev('rotate_rollingstd_12').alias('rotate_rollingstd_12'), \n",
    "                       F.stddev('pressure_rollingstd_12').alias('pressure_rollingstd_12'), \n",
    "                       F.stddev('vibration_rollingstd_12').alias('vibration_rollingstd_12'), \n",
    "                       F.stddev('volt_rollingstd_24').alias('volt_rollingstd_24'),\n",
    "                       F.stddev('rotate_rollingstd_24').alias('rotate_rollingstd_24'), \n",
    "                       F.stddev('pressure_rollingstd_24').alias('pressure_rollingstd_24'), \n",
    "                       F.stddev('vibration_rollingstd_24').alias('vibration_rollingstd_24'),\n",
    "                       F.stddev('volt_rollingstd_36').alias('volt_rollingstd_36'),\n",
    "                       F.stddev('rotate_rollingstd_36').alias('rotate_rollingstd_36'), \n",
    "                       F.stddev('pressure_rollingstd_36').alias('pressure_rollingstd_36'), \n",
    "                       F.stddev('vibration_rollingstd_36').alias('vibration_rollingstd_36'), ))\n",
    "\n",
    "print(telemetry_feat.count())\n",
    "telemetry_feat.where((col(\"machineID\") == 1)).limit(10).toPandas().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Errors features\n",
    "\n",
    "Like telemetry data, errors come with timestamps. An important difference is that the error IDs are categorical values and should not be averaged over time intervals like the telemetry measurements. Instead, we count the number of errors of each type in a lagging window. We begin by reformatting the error data to have one entry per machine per time at which at least one error occurred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "731000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>machineID</th>\n",
       "      <th>dt_truncated</th>\n",
       "      <th>error1sum_rollingmean_24</th>\n",
       "      <th>error2sum_rollingmean_24</th>\n",
       "      <th>error3sum_rollingmean_24</th>\n",
       "      <th>error4sum_rollingmean_24</th>\n",
       "      <th>error5sum_rollingmean_24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>2015-04-27 12:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26</td>\n",
       "      <td>2015-06-28 12:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>2015-08-11 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>2015-03-04 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>2015-04-06 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29</td>\n",
       "      <td>2015-05-14 12:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29</td>\n",
       "      <td>2015-06-20 12:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>29</td>\n",
       "      <td>2015-10-16 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>474</td>\n",
       "      <td>2015-05-29 12:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>474</td>\n",
       "      <td>2015-09-15 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   machineID        dt_truncated  error1sum_rollingmean_24  \\\n",
       "0         26 2015-04-27 12:00:00                       0.0   \n",
       "1         26 2015-06-28 12:00:00                       0.0   \n",
       "2         26 2015-08-11 00:00:00                       0.0   \n",
       "3         29 2015-03-04 00:00:00                       0.0   \n",
       "4         29 2015-04-06 00:00:00                       0.0   \n",
       "5         29 2015-05-14 12:00:00                       0.0   \n",
       "6         29 2015-06-20 12:00:00                       0.0   \n",
       "7         29 2015-10-16 00:00:00                       0.0   \n",
       "8        474 2015-05-29 12:00:00                       0.0   \n",
       "9        474 2015-09-15 00:00:00                       0.0   \n",
       "\n",
       "   error2sum_rollingmean_24  error3sum_rollingmean_24  \\\n",
       "0                       0.0                       0.0   \n",
       "1                       0.0                       0.0   \n",
       "2                       0.0                       0.0   \n",
       "3                       0.0                       0.0   \n",
       "4                       0.0                       0.0   \n",
       "5                       0.0                       0.0   \n",
       "6                       0.0                       0.0   \n",
       "7                       0.0                       0.0   \n",
       "8                       0.0                       0.0   \n",
       "9                       0.0                       0.0   \n",
       "\n",
       "   error4sum_rollingmean_24  error5sum_rollingmean_24  \n",
       "0                       0.0                       0.0  \n",
       "1                       0.0                       0.0  \n",
       "2                       0.0                       0.0  \n",
       "3                       0.0                       0.0  \n",
       "4                       0.0                       0.0  \n",
       "5                       0.0                       0.0  \n",
       "6                       0.0                       0.0  \n",
       "7                       0.0                       0.0  \n",
       "8                       0.0                       0.0  \n",
       "9                       0.0                       0.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a column for each errorID \n",
    "error_ind = (errors.groupBy(\"machineID\",\"datetime\",\"errorID\").pivot('errorID')\n",
    "             .agg(F.count('machineID').alias('dummy')).drop('errorID').fillna(0)\n",
    "             .groupBy(\"machineID\",\"datetime\")\n",
    "             .agg(F.sum('error1').alias('error1sum'), \n",
    "                  F.sum('error2').alias('error2sum'), \n",
    "                  F.sum('error3').alias('error3sum'), \n",
    "                  F.sum('error4').alias('error4sum'), \n",
    "                  F.sum('error5').alias('error5sum')))\n",
    "\n",
    "# join the telemetry data with errors\n",
    "error_count = (telemetry.join(error_ind, \n",
    "                              ((telemetry['machineID'] == error_ind['machineID']) \n",
    "                               & (telemetry['datetime'] == error_ind['datetime'])), \"left\")\n",
    "               .drop('volt', 'rotate', 'pressure', 'vibration')\n",
    "               .drop(error_ind.machineID).drop(error_ind.datetime)\n",
    "               .fillna(0))\n",
    "\n",
    "error_features = ['error1sum','error2sum', 'error3sum', 'error4sum', 'error5sum']\n",
    "\n",
    "wSpec = Window.partitionBy('machineID').orderBy('datetime').rowsBetween(1-24, 0)\n",
    "for col_name in error_features:\n",
    "    # We're only interested in the erros in the previous 24 hours.\n",
    "    error_count = error_count.withColumn(col_name+'_rollingmean_24', \n",
    "                                         F.avg(col(col_name)).over(wSpec))\n",
    "\n",
    "error_feat = (error_count.withColumn(\"dt_truncated\", dt_truncated)\n",
    "              .drop('error1sum', 'error2sum', 'error3sum', 'error4sum', 'error5sum').fillna(0)\n",
    "              .groupBy(\"machineID\",\"dt_truncated\")\n",
    "              .agg(F.mean('error1sum_rollingmean_24').alias('error1sum_rollingmean_24'), \n",
    "                   F.mean('error2sum_rollingmean_24').alias('error2sum_rollingmean_24'), \n",
    "                   F.mean('error3sum_rollingmean_24').alias('error3sum_rollingmean_24'), \n",
    "                   F.mean('error4sum_rollingmean_24').alias('error4sum_rollingmean_24'), \n",
    "                   F.mean('error5sum_rollingmean_24').alias('error5sum_rollingmean_24')))\n",
    "\n",
    "print(error_feat.count())\n",
    "error_feat.limit(10).toPandas().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Days since last replacement from maintenance \n",
    "\n",
    "A crucial data set in this example is the maintenance records which contain the information of component replacement records. Possible features from this data set can be, for example, the number of replacements of each component in the last 3 months to incorporate the frequency of replacements. However, more relevent information would be to calculate how long it has been since a component is last replaced as that would be expected to correlate better with component failures since the longer a component is used, the more degradation should be expected.\n",
    "\n",
    "As a side note, creating lagging features from maintenance data is not as straightforward as for telemetry and errors, so the features from this data are generated in a more custom way. This type of ad-hoc feature engineering is very common in predictive maintenance since domain knowledge plays a crucial role in understanding the predictors of a problem. In the following, the days since last component replacement are calculated for each component type as features from the maintenance data.\n",
    "\n",
    "We start by counting the component replacements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25121\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>machineID</th>\n",
       "      <th>datetime_maint</th>\n",
       "      <th>comp1sum</th>\n",
       "      <th>comp2sum</th>\n",
       "      <th>comp3sum</th>\n",
       "      <th>comp4sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>191</td>\n",
       "      <td>2015-12-28 06:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>567</td>\n",
       "      <td>2015-09-17 06:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>301</td>\n",
       "      <td>2015-04-04 06:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>852</td>\n",
       "      <td>2015-06-14 06:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>942</td>\n",
       "      <td>2015-09-23 06:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>66</td>\n",
       "      <td>2015-09-30 06:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>370</td>\n",
       "      <td>2015-07-22 06:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>512</td>\n",
       "      <td>2015-05-03 06:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>427</td>\n",
       "      <td>2015-06-15 06:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>490</td>\n",
       "      <td>2015-10-26 06:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   machineID       datetime_maint  comp1sum  comp2sum  comp3sum  comp4sum\n",
       "0        191  2015-12-28 06:00:00         1         0         0         0\n",
       "1        567  2015-09-17 06:00:00         0         0         0         1\n",
       "2        301  2015-04-04 06:00:00         1         1         0         0\n",
       "3        852  2015-06-14 06:00:00         0         0         1         0\n",
       "4        942  2015-09-23 06:00:00         0         0         1         1\n",
       "5         66  2015-09-30 06:00:00         0         0         1         0\n",
       "6        370  2015-07-22 06:00:00         0         1         0         1\n",
       "7        512  2015-05-03 06:00:00         0         0         1         0\n",
       "8        427  2015-06-15 06:00:00         0         0         1         1\n",
       "9        490  2015-10-26 06:00:00         1         1         0         0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a column for each component replacement\n",
    "maint_replace = (maint.groupBy(\"machineID\",\"datetime\",\"comp\").pivot('comp')\n",
    "                 .agg(F.count('machineID').alias('dummy')).fillna(0)\n",
    "                 .groupBy(\"machineID\",\"datetime\")\n",
    "                 .agg(F.sum('comp1').alias('comp1sum'), \n",
    "                      F.sum('comp2').alias('comp2sum'), \n",
    "                      F.sum('comp3').alias('comp3sum'),\n",
    "                      F.sum('comp4').alias('comp4sum')))\n",
    "\n",
    "maint_replace = maint_replace.withColumnRenamed('datetime','datetime_maint')\n",
    "\n",
    "print(maint_replace.count())\n",
    "maint_replace.limit(10).toPandas().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features are created by tracking the number of days between each component replacement. We'll repeat these calculations for each of the four components, and join them together into a maintenance feature table.\n",
    "\n",
    "First `comp1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3254437\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>machineID</th>\n",
       "      <th>datetime_tel</th>\n",
       "      <th>sincelastcomp1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>625</td>\n",
       "      <td>2015-01-01 12:00:00</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>625</td>\n",
       "      <td>2015-01-02 00:00:00</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>625</td>\n",
       "      <td>2015-01-02 12:00:00</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>625</td>\n",
       "      <td>2015-01-03 00:00:00</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>625</td>\n",
       "      <td>2015-01-03 12:00:00</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>625</td>\n",
       "      <td>2015-01-04 00:00:00</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>625</td>\n",
       "      <td>2015-01-04 12:00:00</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>625</td>\n",
       "      <td>2015-01-05 00:00:00</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>625</td>\n",
       "      <td>2015-01-05 12:00:00</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>625</td>\n",
       "      <td>2015-01-06 00:00:00</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>625</td>\n",
       "      <td>2015-01-06 12:00:00</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>625</td>\n",
       "      <td>2015-01-07 00:00:00</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>625</td>\n",
       "      <td>2015-01-07 12:00:00</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>625</td>\n",
       "      <td>2015-01-08 00:00:00</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>625</td>\n",
       "      <td>2015-01-08 12:00:00</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>625</td>\n",
       "      <td>2015-01-09 00:00:00</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>625</td>\n",
       "      <td>2015-01-09 12:00:00</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>625</td>\n",
       "      <td>2015-01-10 00:00:00</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>625</td>\n",
       "      <td>2015-01-10 12:00:00</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>625</td>\n",
       "      <td>2015-01-11 00:00:00</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    machineID        datetime_tel  sincelastcomp1\n",
       "0         625 2015-01-01 12:00:00              94\n",
       "1         625 2015-01-02 00:00:00              95\n",
       "2         625 2015-01-02 12:00:00              95\n",
       "3         625 2015-01-03 00:00:00              96\n",
       "4         625 2015-01-03 12:00:00              96\n",
       "5         625 2015-01-04 00:00:00              97\n",
       "6         625 2015-01-04 12:00:00              97\n",
       "7         625 2015-01-05 00:00:00              98\n",
       "8         625 2015-01-05 12:00:00              98\n",
       "9         625 2015-01-06 00:00:00              99\n",
       "10        625 2015-01-06 12:00:00              99\n",
       "11        625 2015-01-07 00:00:00             100\n",
       "12        625 2015-01-07 12:00:00             100\n",
       "13        625 2015-01-08 00:00:00             101\n",
       "14        625 2015-01-08 12:00:00             101\n",
       "15        625 2015-01-09 00:00:00             102\n",
       "16        625 2015-01-09 12:00:00             102\n",
       "17        625 2015-01-10 00:00:00             103\n",
       "18        625 2015-01-10 12:00:00             103\n",
       "19        625 2015-01-11 00:00:00             104"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We want to align the component information on telemetry features timestamps.\n",
    "telemetry_times = (telemetry_feat.select(telemetry_feat.machineID, telemetry_feat.dt_truncated)\n",
    "                   .withColumnRenamed('dt_truncated','datetime_tel'))\n",
    "\n",
    "# Grab component 1 records\n",
    "maint_comp1 = (maint_replace.where(col(\"comp1sum\") == '1').withColumnRenamed('datetime','datetime_maint')\n",
    "               .drop('comp2sum', 'comp3sum', 'comp4sum'))\n",
    "\n",
    "# Within each machine, get the last replacement date for each timepoint\n",
    "maint_tel_comp1 = (telemetry_times.join(maint_comp1, \n",
    "                                        ((telemetry_times ['machineID']== maint_comp1['machineID']) \n",
    "                                         & (telemetry_times ['datetime_tel'] > maint_comp1['datetime_maint']) \n",
    "                                         & ( maint_comp1['comp1sum'] == '1')))\n",
    "                   .drop(maint_comp1.machineID))\n",
    "\n",
    "# Calculate the number of days between replacements\n",
    "comp1 = (maint_tel_comp1.withColumn(\"sincelastcomp1\", \n",
    "                                    datediff(maint_tel_comp1.datetime_tel, maint_tel_comp1.datetime_maint))\n",
    "         .drop(maint_tel_comp1.datetime_maint).drop(maint_tel_comp1.comp1sum))\n",
    "\n",
    "print(comp1.count())\n",
    "comp1.filter(comp1.machineID == '625').orderBy(comp1.datetime_tel).limit(20).toPandas().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then `comp2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3278730\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>machineID</th>\n",
       "      <th>datetime_tel</th>\n",
       "      <th>sincelastcomp2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>625</td>\n",
       "      <td>2015-01-01 12:00:00</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>625</td>\n",
       "      <td>2015-01-02 00:00:00</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>625</td>\n",
       "      <td>2015-01-02 12:00:00</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>625</td>\n",
       "      <td>2015-01-03 00:00:00</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>625</td>\n",
       "      <td>2015-01-03 12:00:00</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   machineID        datetime_tel  sincelastcomp2\n",
       "0        625 2015-01-01 12:00:00              19\n",
       "1        625 2015-01-02 00:00:00              20\n",
       "2        625 2015-01-02 12:00:00              20\n",
       "3        625 2015-01-03 00:00:00              21\n",
       "4        625 2015-01-03 12:00:00              21"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab component 2 records\n",
    "maint_comp2 = (maint_replace.where(col(\"comp2sum\") == '1').withColumnRenamed('datetime','datetime_maint')\n",
    "               .drop('comp1sum', 'comp3sum', 'comp4sum'))\n",
    "\n",
    "# Within each machine, get the last replacement date for each timepoint\n",
    "maint_tel_comp2 = (telemetry_times.join(maint_comp2, \n",
    "                                        ((telemetry_times ['machineID']== maint_comp2['machineID']) \n",
    "                                         & (telemetry_times ['datetime_tel'] > maint_comp2['datetime_maint']) \n",
    "                                         & ( maint_comp2['comp2sum'] == '1')))\n",
    "                   .drop(maint_comp2.machineID))\n",
    "\n",
    "# Calculate the number of days between replacements\n",
    "comp2 = (maint_tel_comp2.withColumn(\"sincelastcomp2\", \n",
    "                                    datediff(maint_tel_comp2.datetime_tel, maint_tel_comp2.datetime_maint))\n",
    "         .drop(maint_tel_comp2.datetime_maint).drop(maint_tel_comp2.comp2sum))\n",
    "\n",
    "print(comp2.count())\n",
    "comp2.filter(comp2.machineID == '625').orderBy(comp2.datetime_tel).limit(5).toPandas().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then `comp3`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3345413\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>machineID</th>\n",
       "      <th>datetime_tel</th>\n",
       "      <th>sincelastcomp3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>625</td>\n",
       "      <td>2015-01-01 12:00:00</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>625</td>\n",
       "      <td>2015-01-02 00:00:00</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>625</td>\n",
       "      <td>2015-01-02 12:00:00</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>625</td>\n",
       "      <td>2015-01-03 00:00:00</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>625</td>\n",
       "      <td>2015-01-03 12:00:00</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   machineID        datetime_tel  sincelastcomp3\n",
       "0        625 2015-01-01 12:00:00              19\n",
       "1        625 2015-01-02 00:00:00              20\n",
       "2        625 2015-01-02 12:00:00              20\n",
       "3        625 2015-01-03 00:00:00              21\n",
       "4        625 2015-01-03 12:00:00              21"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab component 3 records\n",
    "maint_comp3 = (maint_replace.where(col(\"comp3sum\") == '1').withColumnRenamed('datetime','datetime_maint')\n",
    "               .drop('comp1sum', 'comp2sum', 'comp4sum'))\n",
    "\n",
    "# Within each machine, get the last replacement date for each timepoint\n",
    "maint_tel_comp3 = (telemetry_times.join(maint_comp3, ((telemetry_times ['machineID']==maint_comp3['machineID']) \n",
    "                                                      & (telemetry_times ['datetime_tel'] > maint_comp3['datetime_maint']) \n",
    "                                                      & ( maint_comp3['comp3sum'] == '1')))\n",
    "                   .drop(maint_comp3.machineID))\n",
    "\n",
    "# Calculate the number of days between replacements\n",
    "comp3 = (maint_tel_comp3.withColumn(\"sincelastcomp3\", \n",
    "                                    datediff(maint_tel_comp3.datetime_tel, maint_tel_comp3.datetime_maint))\n",
    "         .drop(maint_tel_comp3.datetime_maint).drop(maint_tel_comp3.comp3sum))\n",
    "\n",
    "\n",
    "print(comp3.count())\n",
    "comp3.filter(comp3.machineID == '625').orderBy(comp3.datetime_tel).limit(5).toPandas().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then `comp4`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab component 4 records\n",
    "maint_comp4 = (maint_replace.where(col(\"comp4sum\") == '1').withColumnRenamed('datetime','datetime_maint')\n",
    "               .drop('comp1sum', 'comp2sum', 'comp3sum'))\n",
    "\n",
    "# Within each machine, get the last replacement date for each timepoint\n",
    "maint_tel_comp4 = telemetry_times.join(maint_comp4, ((telemetry_times['machineID']==maint_comp4['machineID']) \n",
    "                                                     & (telemetry_times['datetime_tel'] > maint_comp4['datetime_maint']) \n",
    "                                                     & (maint_comp4['comp4sum'] == '1'))).drop(maint_comp4.machineID)\n",
    "\n",
    "# Calculate the number of days between replacements\n",
    "comp4 = (maint_tel_comp4.withColumn(\"sincelastcomp4\", \n",
    "                                    datediff(maint_tel_comp4.datetime_tel, maint_tel_comp4.datetime_maint))\n",
    "         .drop(maint_tel_comp4.datetime_maint).drop(maint_tel_comp4.comp4sum))\n",
    "\n",
    "print(comp4.count())\n",
    "comp4.filter(comp4.machineID == '625').orderBy(comp4.datetime_tel).limit(5).toPandas().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we join the four component replacement tables together. once joined we take the average across 3 hour observation windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join component 3 and 4\n",
    "comp3_4 = (comp3.join(comp4, ((comp3['machineID'] == comp4['machineID']) \n",
    "                              & (comp3['datetime_tel'] == comp4['datetime_tel'])), \"left\")\n",
    "           .drop(comp4.machineID).drop(comp4.datetime_tel))\n",
    "\n",
    "# Join component 2 to 3 and 4\n",
    "comp2_3_4 = (comp2.join(comp3_4, ((comp2['machineID'] == comp3_4['machineID']) \n",
    "                                  & (comp2['datetime_tel'] == comp3_4['datetime_tel'])), \"left\")\n",
    "             .drop(comp3_4.machineID).drop(comp3_4.datetime_tel))\n",
    "\n",
    "# Join component 1 to 2, 3 and 4\n",
    "comps_feat = (comp1.join(comp2_3_4, ((comp1['machineID'] == comp2_3_4['machineID']) \n",
    "                                      & (comp1['datetime_tel'] == comp2_3_4['datetime_tel'])), \"left\")\n",
    "               .drop(comp2_3_4.machineID).drop(comp2_3_4.datetime_tel)\n",
    "               .groupBy(\"machineID\", \"datetime_tel\")\n",
    "               .agg(F.max('sincelastcomp1').alias('sincelastcomp1'), \n",
    "                    F.max('sincelastcomp2').alias('sincelastcomp2'), \n",
    "                    F.max('sincelastcomp3').alias('sincelastcomp3'), \n",
    "                    F.max('sincelastcomp4').alias('sincelastcomp4'))\n",
    "               .fillna(0))\n",
    "\n",
    "# Choose the 3 hour timestamps to align the data\n",
    "dt_truncated = ((round(unix_timestamp(col(\"datetime_tel\")) / time_val) * time_val).cast(\"timestamp\"))\n",
    "\n",
    "# Collect data\n",
    "maint_feat = (comps_feat.withColumn(\"dt_truncated\", dt_truncated)\n",
    "              .groupBy(\"machineID\",\"dt_truncated\")\n",
    "              .agg(F.mean('sincelastcomp1').alias('comp1sum'), \n",
    "                   F.mean('sincelastcomp2').alias('comp2sum'), \n",
    "                   F.mean('sincelastcomp3').alias('comp3sum'), \n",
    "                   F.mean('sincelastcomp4').alias('comp4sum')))\n",
    "\n",
    "print(maint_feat.count())\n",
    "maint_feat.limit(10).toPandas().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine features\n",
    "\n",
    "The machine features can be used without further modification. These include descriptive information about the type of each machine and its age (number of years in service). If the age information had been recorded as a \"first use date\" for each machine, a transformation would have been necessary to turn those into a numeric values indicating the years in service.\n",
    "\n",
    "We do need to create a set of dummy features, boolean variables to indicate the model name of the machine. This is a _one-hot encoding_ step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding of the variable model, basically creates a set of dummy boolean variables\n",
    "catVarNames = ['model']  \n",
    "sIndexers = [StringIndexer(inputCol=x, outputCol=x + '_indexed') for x in catVarNames]\n",
    "machines_cat = Pipeline(stages=sIndexers).fit(machines).transform(machines)\n",
    "\n",
    "# one-hot encode\n",
    "ohEncoders = [OneHotEncoder(inputCol=x + '_indexed', outputCol=x + '_encoded')\n",
    "              for x in catVarNames]\n",
    "\n",
    "ohPipelineModel = Pipeline(stages=ohEncoders).fit(machines_cat)\n",
    "machines_cat = ohPipelineModel.transform(machines_cat)\n",
    "\n",
    "drop_list = [col_n for col_n in machines_cat.columns if 'indexed' in col_n]\n",
    "\n",
    "machines_feat = machines_cat.select([column for column in machines_cat.columns if column not in drop_list])\n",
    "\n",
    "print(machines_feat.count())\n",
    "machines_feat.limit(10).toPandas().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging feature data\n",
    "\n",
    "Next, we merge the telemetry, maintenance, machine and error feature data sets into a large feature data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join error features with component maintenance features\n",
    "error_maint = (error_feat.join(maint_feat, \n",
    "                               ((error_feat['machineID'] == maint_feat['machineID']) \n",
    "                                & (error_feat['dt_truncated'] == maint_feat['dt_truncated'])), \"left\")\n",
    "               .drop(maint_feat.machineID).drop(maint_feat.dt_truncated))\n",
    "\n",
    "# now join that with machines features\n",
    "error_maint_feat = (error_maint.join(machines_feat, \n",
    "                                     ((error_maint['machineID'] == machines_feat['machineID'])), \"left\")\n",
    "                    .drop(machines_feat.machineID))\n",
    "\n",
    "# Clean up some unecessary columns\n",
    "error_maint_feat = error_maint_feat.select([c for c in error_maint_feat.columns if c not in \n",
    "                                            {'error1sum', 'error2sum', 'error3sum', 'error4sum', 'error5sum'}])\n",
    "\n",
    "# join telemetry_all with error/maint/machine features to create final feature matrix\n",
    "final_feat = (telemetry_feat.join(error_maint_feat, \n",
    "                                  ((telemetry_feat['machineID'] == error_maint_feat['machineID']) \n",
    "                                   & (telemetry_feat['dt_truncated'] == error_maint_feat['dt_truncated'])), \"left\")\n",
    "              .drop(error_maint_feat.machineID).drop(error_maint_feat.dt_truncated))\n",
    "\n",
    "print(final_feat.count())\n",
    "final_feat.filter(final_feat.machineID == '625').orderBy(final_feat.dt_truncated).limit(10).toPandas().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label construction\n",
    "\n",
    "When using multi-class classification for predicting failures, labelling is done by taking a time window prior to the failure of an asset and labelling the feature records that fall into that window as \"as \"about to fail\" while labelling all other records as normal.\" This time window should be picked according to the business case: in some situations it may be enough to predict failures hours in advance, while in others days or weeks may be needed e.g. for arrival of replacement parts.\n",
    "\n",
    "The prediction problem for this example scenerio is to estimate the probability that a machine will fail in the near future due to a failure of a certain component. More specifically, the goal is to compute the probability that a machine will fail in the next 24 hours due to a certain component failure (component 1, 2, 3, or 4). Below, a categorical failure feature is created to serve as the label. All records within a 24 hour window before a failure of component 1 have failure=comp1, and so on for components 2, 3, and 4; all records not within 24 hours of a component failure have failure=none."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map the failure data to final feature matrix\n",
    "labeled_features = (final_feat.join(failures, \n",
    "                                    ((final_feat['machineID'] == failures['machineID']) \n",
    "                                     & (final_feat['dt_truncated'] == failures['datetime'])), \"left\")\n",
    "                    .drop(failures.machineID).drop(failures.datetime)\n",
    "                    .withColumn('failure', F.when(col('failure') == \"comp1\", 1.0).otherwise(col('failure')))\n",
    "                    .withColumn('failure', F.when(col('failure') == \"comp2\", 2.0).otherwise(col('failure')))\n",
    "                    .withColumn('failure', F.when(col('failure') == \"comp3\", 3.0).otherwise(col('failure')))\n",
    "                    .withColumn('failure', F.when(col('failure') == \"comp4\", 4.0).otherwise(col('failure'))))\n",
    "\n",
    "labeled_features = (labeled_features.withColumn(\"failure\", \n",
    "                                                labeled_features.failure.cast(DoubleType()))\n",
    "                    .fillna(0))\n",
    "\n",
    "print(labeled_features.count())\n",
    "labeled_features.limit(10).toPandas().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels are created failed during each of the 7 days before the actual failure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lag values to manually backfill label (bfill =7)\n",
    "my_window = Window.partitionBy('machineID').orderBy(labeled_features.dt_truncated.desc())\n",
    "\n",
    "# Create the previous 7 days \n",
    "labeled_features = labeled_features.withColumn(\"prev_value1\", F.lag(labeled_features.failure).over(my_window)).fillna(0) \n",
    "labeled_features = labeled_features.withColumn(\"prev_value2\", F.lag(labeled_features.prev_value1).over(my_window)).fillna(0) \n",
    "labeled_features = labeled_features.withColumn(\"prev_value3\", F.lag(labeled_features.prev_value2).over(my_window)).fillna(0) \n",
    "labeled_features = labeled_features.withColumn(\"prev_value4\", F.lag(labeled_features.prev_value3).over(my_window)).fillna(0) \n",
    "labeled_features = labeled_features.withColumn(\"prev_value5\", F.lag(labeled_features.prev_value4).over(my_window)).fillna(0) \n",
    "labeled_features = labeled_features.withColumn(\"prev_value6\", F.lag(labeled_features.prev_value5).over(my_window)).fillna(0)\n",
    "labeled_features = labeled_features.withColumn(\"prev_value7\", F.lag(labeled_features.prev_value6).over(my_window)).fillna(0)\n",
    "\n",
    "# Create a label features\n",
    "labeled_features = (labeled_features.withColumn('label', labeled_features.failure + labeled_features.prev_value1 \n",
    "                                                + labeled_features.prev_value2 + labeled_features.prev_value3 \n",
    "                                                + labeled_features.prev_value4 + labeled_features.prev_value5 \n",
    "                                                + labeled_features.prev_value6 + labeled_features.prev_value7))\n",
    "\n",
    "# Restrict the label to be on the range of 0:4, and remove extra columns\n",
    "labeled_features = (labeled_features.withColumn('label_e', F.when(col('label') > 4, 4.0).otherwise(col('label')))\n",
    "                    .drop(labeled_features.prev_value1).drop(labeled_features.prev_value2)\n",
    "                    .drop(labeled_features.prev_value3).drop(labeled_features.prev_value4)\n",
    "                    .drop(labeled_features.prev_value5).drop(labeled_features.prev_value6)\n",
    "                    .drop(labeled_features.prev_value7).drop(labeled_features.label))\n",
    "\n",
    "print(labeled_features.count())\n",
    "labeled_features.limit(10).toPandas().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get an idea of how labelling works, we plot the labels for 4 machines below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_dta = (labeled_features.filter(labeled_features.label_e > 0)\n",
    "           .where(col(\"machineID\").isin({\"65\", \"558\", \"222\", \"965\"}))\n",
    "           .select(labeled_features.machineID, labeled_features.dt_truncated, labeled_features.label_e)\n",
    "           .toPandas())\n",
    "\n",
    "# format datetime field which comes in as string\n",
    "plt_dta['dt_truncated'] = pd.to_datetime(plt_dta['dt_truncated'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "plt_dta.label_e = plt_dta.label_e.astype(int)\n",
    "\n",
    "ggplot(aes(x=\"dt_truncated\", y=\"label_e\", color=\"label_e\"), plt_dta) +\\\n",
    "    geom_point()+\\\n",
    "    xlab(\"Date\") + ylab(\"Component Number\") +\\\n",
    "    scale_x_date(labels=date_format('%m-%d')) +\\\n",
    "    scale_color_brewer(type = 'seq', palette = 'BuGn') +\\\n",
    "    facet_grid('machineID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that most of the days are marked as healthy (label = 0 are omitted for plot performance, though the dates are still accurate). Each of the four machines have multiple failures over the course of the dataset. Each labeled failure includes the date of failure and the previous seven days, all are marked with the number indicating the component that failed. \n",
    "\n",
    "The goal of the model will be to predict when a failure will occur and which component will fail simultaneously. This will be a multiclass classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Write the feature data to cloud storage\n",
    "\n",
    "Write the final labeled feature data as parquet file an Azure blob storage container. For technical details, see:\n",
    "https://github.com/Azure/ViennaDocs/blob/master/Documentation/UsingBlobForStorage.md\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new container if necessary, otherwise you can use an existing container.\n",
    "# This command creates the container if it does not already exist. Else it does nothing.\n",
    "az_blob_service.create_container(STORAGE_CONTAINER_NAME, \n",
    "                                 fail_on_exist=False, \n",
    "                                 public_access=PublicAccess.Container)\n",
    "\n",
    "# Write labeled feature data to blob for use in the next notebook\n",
    "labeled_features.write.mode('overwrite').parquet(FEATURES_LOCAL_DIRECT)\n",
    "\n",
    "# Delete the old data.\n",
    "for blob in az_blob_service.list_blobs(STORAGE_CONTAINER_NAME):\n",
    "    if FEATURES_LOCAL_DIRECT in blob.name:\n",
    "        az_blob_service.delete_blob(STORAGE_CONTAINER_NAME, blob.name)\n",
    "\n",
    "# upload the entire folder into blob storage\n",
    "for name in glob.iglob(FEATURES_LOCAL_DIRECT + '/*'):\n",
    "    print(os.path.abspath(name))\n",
    "    az_blob_service.create_blob_from_path(STORAGE_CONTAINER_NAME, name, name)\n",
    "\n",
    "print(\"Feature engineering final dataset files saved!\")\n",
    "\n",
    "# Time the notebook execution. \n",
    "# This will only make sense if you \"Run All\" cells\n",
    "toc = time.time()\n",
    "print(\"Full run took %.2f minutes\" % ((toc - tic)/60))\n",
    "\n",
    "logger.log(\"Feature Engineering Run time\", ((toc - tic)/60))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "The next step is to build and compare machine learning models using the feature data set we have just created. The `Code\\3_model_building.ipynb` notebook works through building a Decision Tree Classifier and a Random Forest Classifier using this data set. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdm LDSVM",
   "language": "python",
   "name": "pdm_ldsvm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

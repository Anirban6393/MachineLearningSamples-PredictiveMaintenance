{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4c: Creating the scoring file for deployment\n",
    "\n",
    "The best model is now saved as a .model file along with the relevant scheme for deployment. The functions are first tested locally before operationalizing the model using Azure Machine Learning Model Management environment for use in production in realtime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First check to ensure that the latest version of the azure-ml-api-sdk is available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied (use --upgrade to upgrade): azure-ml-api-sdk in c:\\users\\jaymathe\\appdata\\local\\amlworkbench\\python\\lib\\site-packages\n",
      "Requirement already satisfied (use --upgrade to upgrade): python-dateutil in c:\\users\\jaymathe\\appdata\\local\\amlworkbench\\python\\lib\\site-packages (from azure-ml-api-sdk)\n",
      "Requirement already satisfied (use --upgrade to upgrade): pytz in c:\\users\\jaymathe\\appdata\\local\\amlworkbench\\python\\lib\\site-packages (from azure-ml-api-sdk)\n",
      "Requirement already satisfied (use --upgrade to upgrade): liac-arff in c:\\users\\jaymathe\\appdata\\local\\amlworkbench\\python\\lib\\site-packages (from azure-ml-api-sdk)\n",
      "Requirement already satisfied (use --upgrade to upgrade): six>=1.5 in c:\\users\\jaymathe\\appdata\\local\\amlworkbench\\python\\lib\\site-packages (from python-dateutil->azure-ml-api-sdk)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 8.1.2, however version 9.0.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install azure-ml-api-sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ml.api.schema.dataTypes import DataTypes\n",
    "from azure.ml.api.schema.sampleDefinition import SampleDefinition\n",
    "from azure.ml.api.realtime.services import generate_schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define init and run \n",
    "\n",
    "We start by defining our init and run functions in the cell below. Then write them to the score.py file. This file will load the model, perform the prediction, and return the result.\n",
    "\n",
    "The init function initializes your web service, loading in any data or models that you need to score your inputs. In the example below, we load in the trained model. This command is run when the Docker contianer containing your service initializes.\n",
    "\n",
    "The run function defines what is executed on a scoring call. In our simple example, we simply load in the input as a data frame, and run our pipeline on the input, and return the prediction.\n",
    "\n",
    "The %%writefile command will save the score.py file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting pdmscore.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile pdmscore.py\n",
    "# after testing the below init() and run() functions,\n",
    "# uncomment this cell to create the score.py after.\n",
    "\n",
    "# remove import from init() from function.\n",
    "\n",
    "from pyspark import SparkConf\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SQLContext\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import concat, col, udf, lag, date_add, explode, lit, unix_timestamp\n",
    "from pyspark.sql.functions import month, weekofyear, dayofmonth\n",
    "from pyspark.sql.functions import datediff, to_date, lit, unix_timestamp\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.types import DateType\n",
    "from pyspark.sql.dataframe import *\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.classification import *\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, VectorIndexer\n",
    "from pyspark.ml.feature import StandardScaler, PCA, RFormula\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.mllib.stat import Statistics\n",
    "from pyspark.sql.functions import UserDefinedFunction\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from azureml.api.schema.dataTypes import DataTypes\n",
    "from azureml.api.schema.sampleDefinition import SampleDefinition\n",
    "from azureml.api.realtime.services import generate_schema\n",
    "\n",
    "\n",
    "def init():\n",
    "    # read in the model file\n",
    "    from pyspark.ml import PipelineModel\n",
    "    global pipeline\n",
    "    pipeline = PipelineModel.load(\"/azureml-share/pdmrfull.model\")\n",
    "    \n",
    "def run(input_df):\n",
    "    import json\n",
    "    response = ''\n",
    "    \n",
    "    try:\n",
    "        #Get prediction results for the dataframe\n",
    "        input_features = [\n",
    "            'volt_rollingmean_3',\n",
    "            'rotate_rollingmean_3',\n",
    "            'pressure_rollingmean_3',\n",
    "            'vibration_rollingmean_3',\n",
    "            'volt_rollingmean_24',\n",
    "            'rotate_rollingmean_24',\n",
    "            'pressure_rollingmean_24',\n",
    "            'vibration_rollingmean_24',\n",
    "            'volt_rollingstd_3',\n",
    "            'rotate_rollingstd_3',\n",
    "            'pressure_rollingstd_3',\n",
    "            'vibration_rollingstd_3',\n",
    "            'volt_rollingstd_24',\n",
    "            'rotate_rollingstd_24',\n",
    "            'pressure_rollingstd_24',\n",
    "            'vibration_rollingstd_24',\n",
    "            'error1sum_rollingmean_24',\n",
    "            'error2sum_rollingmean_24',\n",
    "            'error3sum_rollingmean_24',\n",
    "            'error4sum_rollingmean_24',\n",
    "            'error5sum_rollingmean_24',\n",
    "            'comp1sum',\n",
    "            'comp2sum',\n",
    "            'comp3sum',\n",
    "            'comp4sum',\n",
    "            'age',\n",
    "        ]\n",
    "\n",
    "        va = VectorAssembler(inputCols=(input_features), outputCol='features')\n",
    "        data = va.transform(input_df).select('machineID','features')\n",
    "        score = pipeline.transform(data)\n",
    "        predictions = score.collect()\n",
    "\n",
    "        #Get each scored result\n",
    "        preds = [str(x['prediction']) for x in predictions]\n",
    "        response = \",\".join(preds)\n",
    "    except Exception as e:\n",
    "        print(\"Error: {0}\",str(e))\n",
    "        return (str(e))\n",
    "    \n",
    "    # Return results\n",
    "    print(json.dumps(response))\n",
    "    return json.dumps(response)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    init()\n",
    "    run(\"{\\\"input_df\\\":[{\\\"machineID\\\":114,\\\"volt_rollingmean_3\\\":163.375732902,\\\"rotate_rollingmean_3\\\":333.149484586,\\\"pressure_rollingmean_3\\\":100.183951698,\\\"vibration_rollingmean_3\\\":44.0958812638,\\\"volt_rollingmean_24\\\":164.114723991,\\\"rotate_rollingmean_24\\\":277.191815232,\\\"pressure_rollingmean_24\\\":97.6289110707,\\\"vibration_rollingmean_24\\\":50.8853505161,\\\"volt_rollingstd_3\\\":21.0049565219,\\\"rotate_rollingstd_3\\\":67.5287259378,\\\"pressure_rollingstd_3\\\":12.9361526861,\\\"vibration_rollingstd_3\\\":4.61359760918,\\\"volt_rollingstd_24\\\":15.5377738062,\\\"rotate_rollingstd_24\\\":67.6519885441,\\\"pressure_rollingstd_24\\\":10.528274633,\\\"vibration_rollingstd_24\\\":6.94129487555,\\\"error1sum_rollingmean_24\\\":0.0,\\\"error2sum_rollingmean_24\\\":0.0,\\\"error3sum_rollingmean_24\\\":0.0,\\\"error4sum_rollingmean_24\\\":0.0,\\\"error5sum_rollingmean_24\\\":0.0,\\\"comp1sum\\\":489.0,\\\"comp2sum\\\":549.0,\\\"comp3sum\\\":549.0,\\\"comp4sum\\\":564.0,\\\"age\\\":18.0}]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the CLI to deploy and manage your web service \n",
    "\n",
    "## Pre-requisites \n",
    "\n",
    "Use the following commands to set up an environment and account to run the web service. For more info, see the Getting Started Guide and the CLI Command Reference. You can use -h flag at the end of the commands for command help.\n",
    "\n",
    "• Create the environment (you need to do this once per environment e.g. dev or prod)\n",
    "```\n",
    "az ml env setup -c -n <yourclustername> --location <e.g. eastus2>\n",
    "```\n",
    "\n",
    "• Create a Model Management account (one time setup)\n",
    "```\n",
    "az ml account modelmanagement create --location <e.g. eastus2> -n <your-new-acctname> -g <yourresourcegroupname> --sku-instances 1 --sku-name S1\n",
    "```\n",
    "\n",
    "• Set the Model Management account\n",
    "```\n",
    "az ml account modelmanagement set -n <youracctname> -g <yourresourcegroupname>\n",
    "```\n",
    "\n",
    "• Set the environment. The cluster name is the name used in step 1 above. The resource group name was the output of the same process and would be in the command window when the setup process is completed.\n",
    "```\n",
    "az ml env set -n <yourclustername> -g <yourresourcegroupname>\n",
    "```\n",
    "\n",
    "## Deploy your web service \n",
    "\n",
    "Switch to a bash shell, and run the following commands to deploy your service and run it.\n",
    "\n",
    "Enter the path where the notebook and other files are saved. Your actual path may be different from this example.\n",
    "```\n",
    "cd ~/notebooks/azureml/realtime/\n",
    "```\n",
    "\n",
    "This assumes that you saved your model locally.\n",
    "```\n",
    "az ml service create realtime -f pdmscore.py -r  spark-py -m pdmrfull.model -s service_schema.json -n pdmservice --cpu 0.1\n",
    "```\n",
    "\n",
    "This command will return the sample run command with sample data. You can get the Service Id from the output of the create command above.\n",
    "```\n",
    "az ml service show realtime -i <yourserviceid>\n",
    "```\n",
    "\n",
    "Call the web service to get a prediction\n",
    "```\n",
    "az ml service run realtime -i <yourserviceid> -d \"{\\\"input_df\\\": [{\\\"machineID\\\":114, \\\"vo\n",
    "lt_rollingmean_3\\\":163.375732902, \\\"rotate_rollingmean_3\\\":333.149484586, \\\"pressure_rollingmean_3\\\":100.183951698, \\\"vibration_rollingmean_3\\\":44.0958812638, \\\"volt_rollingme\n",
    "an_24\\\":164.114723991, \\\"rotate_rollingmean_24\\\":277.191815232, \\\"pressure_rollingmean_24\\\":97.6289110707, \\\"vibration_rollingmean_24\\\":50.8853505161, \\\"volt_rollingstd_3\\\":21\n",
    ".0049565219, \\\"rotate_rollingstd_3\\\":67.5287259378, \\\"pressure_rollingstd_3\\\":12.9361526861, \\\"vibration_rollingstd_3\\\":4.61359760918, \\\"volt_rollingstd_24\\\":15.5377738062, \\\"\n",
    "rotate_rollingstd_24\\\":67.6519885441, \\\"pressure_rollingstd_24\\\":10.528274633, \\\"vibration_rollingstd_24\\\":6.94129487555, \\\"error1sum_rollingmean_24\\\":0.0, \\\"error2sum_rolling\n",
    "mean_24\\\":0.0, \\\"error3sum_rollingmean_24\\\":0.0, \\\"error4sum_rollingmean_24\\\":0.0, \\\"error5sum_rollingmean_24\\\":0.0, \\\"comp1sum\\\":489.0, \\\"comp2sum\\\":549.0, \\\"comp3sum\\\":549.0\n",
    ", \\\"comp4sum\\\":564.0, \\\"age\\\":180}]}\"\n",
    "```\n",
    "\n",
    "Predicted output label is as follows:\n",
    "```\n",
    "\"0.0\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}